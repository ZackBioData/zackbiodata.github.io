[
  {
    "objectID": "log/index.html",
    "href": "log/index.html",
    "title": "Bioinformatics Logbook",
    "section": "",
    "text": "A logbook documenting my journey through bioinformatics.\n\n\n2025-05-23 ‚Äî Prostate Cancer DEG (GSE6919) bulk RNA sequencing (microarray data) from the GEO dataset GSE6919 to identify genes that are differentially expressed between cancerous and healthy prostate tissues. The analysis was performed using the limma package in R.\n2025-08-04 ‚Äî Mastoparan B Variant Panel (ClinVar)\nUsed a local ClinVar VCF to extract variants in calcium-buffering and metabolic genes that may influence susceptibility to Mastoparan B‚Äìinduced apoptosis. Focused on genes like PCP4, ATP2B1, BCL2, and MYC."
  },
  {
    "objectID": "log/2025-05-23_prostate-limma.html",
    "href": "log/2025-05-23_prostate-limma.html",
    "title": "Prostate Cancer DEG Analysis (GSE6919)",
    "section": "",
    "text": "In this analysis, I used bulk RNA sequencing (microarray data) from the public GEO dataset GSE6919 to investigate differences in gene expression between cancerous and healthy prostate tissues.\nThe aim was to identify differentially expressed genes (DEGs) that could point to disrupted biological processes in prostate cancer, especially with a view toward metabolic shifts or biomarker discovery."
  },
  {
    "objectID": "log/2025-05-23_prostate-limma.html#project-summary",
    "href": "log/2025-05-23_prostate-limma.html#project-summary",
    "title": "Prostate Cancer DEG Analysis (GSE6919)",
    "section": "",
    "text": "In this analysis, I used bulk RNA sequencing (microarray data) from the public GEO dataset GSE6919 to investigate differences in gene expression between cancerous and healthy prostate tissues.\nThe aim was to identify differentially expressed genes (DEGs) that could point to disrupted biological processes in prostate cancer, especially with a view toward metabolic shifts or biomarker discovery."
  },
  {
    "objectID": "log/2025-05-23_prostate-limma.html#methods-overview",
    "href": "log/2025-05-23_prostate-limma.html#methods-overview",
    "title": "Prostate Cancer DEG Analysis (GSE6919)",
    "section": "Methods Overview",
    "text": "Methods Overview\nThe analysis was performed in R using the following packages:\n\nGEOquery ‚Äî to load expression and metadata\n\nlimma ‚Äî for linear modeling of microarray data\n\ntidyverse ‚Äî for data wrangling and exploration\n\nclusterProfiler, org.Hs.eg.db ‚Äî for GO enrichment analysis\n\n\nKey steps:\n\nDownloaded GSE6919 and extracted the expression matrix\n\nCleaned and labeled metadata (e.g.¬†tumor vs.¬†normal)\n\nFit a linear model using limma and contrasted tumor vs.¬†normal\n\nExtracted top upregulated and downregulated genes\n\nPerformed GO enrichment to interpret biological meaning"
  },
  {
    "objectID": "log/2025-05-23_prostate-limma.html#differential-expression-results",
    "href": "log/2025-05-23_prostate-limma.html#differential-expression-results",
    "title": "Prostate Cancer DEG Analysis (GSE6919)",
    "section": "Differential Expression Results",
    "text": "Differential Expression Results\n\nVolcano Plot X axis is change in expression and y value is significance.\n\n\n\nVolcano plot showing DEGs in prostate cancer\n\n\nThis volcano plot shows the spread of differentially expressed genes between tumor and normal tissues. Genes with high log fold-change and low p-values are highlighted.\nThis version of the volcano plot contains unfiltered or duplicated gene symbols and extreme values resulted in alot of messy invalid data scewing graph scale and bad gene labels such as GAPDH.1 and ACTB.1."
  },
  {
    "objectID": "log/2025-05-23_prostate-limma.html#go-enrichment-analysis",
    "href": "log/2025-05-23_prostate-limma.html#go-enrichment-analysis",
    "title": "Prostate Cancer DEG Analysis (GSE6919)",
    "section": "GO Enrichment Analysis",
    "text": "GO Enrichment Analysis\n\nEnriched Biological Processes\n\n\n\n\n\n\n\n\n\n\nGO ID\nBiological Process\nGene Ratio\nAdjusted P-value\nGene Count\n\n\n\n\nGO:0045765\nRegulation of angiogenesis\n11/88\n0.00111\n11\n\n\nGO:1901342\nRegulation of vasculature development\n11/88\n0.00111\n11\n\n\nGO:0002696\nPositive regulation of leukocyte activation\n10/88\n0.00572\n10\n\n\nGO:0050867\nPositive regulation of cell activation\n10/88\n0.00677\n10\n\n\nGO:0051251\nPositive regulation of lymphocyte activation\n9/88\n0.00902\n9\n\n\nGO:0045766\nPositive regulation of angiogenesis\n7/88\n0.00902\n7\n\n\nGO:1904018\nPositive regulation of vasculature development\n7/88\n0.00902\n7\n\n\nGO:0050878\nRegulation of body fluid levels\n9/88\n0.01740\n9\n\n\nGO:0045785\nPositive regulation of cell adhesion\n10/88\n0.02360\n10\n\n\nGO:0050870\nPositive regulation of T cell activation\n7/88\n0.04120\n7\n\n\n\n\n\n\nGO Enrichment Bar Chart\n\n\n\nTop GO terms for prostate cancer DEGs\n\n\nThis bar chart shows the top GO Biological Process categories enriched in the DEGs. Angiogenesis, immune activation, and vasculature development were particularly prominent.\n\n\n\nGenes contributing to enriched biological processes\nRegulation of angiogenesis\nSTAB1, PAK4, NPR1, PRKD2, SASH1, WNK1\nRegulation of vasculature development\nSTAB1, PAK4, NPR1, PRKD2, SASH1, WNK1\nPositive regulation of angiogenesis\nPAK4, PRKD2, SASH1, WNK1, CD40, PDPK1\nPositive regulation of vasculature development\nPAK4, PRKD2, SASH1, WNK1, CD40, PDPK1"
  },
  {
    "objectID": "log/2025-05-23_prostate-limma.html#lessons-learned-for-myself",
    "href": "log/2025-05-23_prostate-limma.html#lessons-learned-for-myself",
    "title": "Prostate Cancer DEG Analysis (GSE6919)",
    "section": "Lessons Learned for myself",
    "text": "Lessons Learned for myself\nPlots didn‚Äôt save ‚Üí forgot ggsave(). Used ggsave(‚Äúfigures/Volcanoplot.jpg‚Äù) and made sure the folder path was right.\nPlots didn‚Äôt render in site ‚Üí wrong relative path. Switched to log/figures/ and renamed files cleanly.\nenrichplot::barplot() didn‚Äôt work ‚Üí Just use barplot() without enrichplot:: prefix.\nPNG wouldn‚Äôt load ‚Üí renamed .png and re-saved properly. Hosted on Imgur as backup.\nHad to clean probe ‚Üí gene symbol mapping ‚Üí mapIds() gave NAs. Filtered out before topTable / enrichment.\nSaved a bunch of useful code in .Rhistory ‚Äî rescued a lot from there when I thought it was lost."
  },
  {
    "objectID": "log/2025-05-23_prostate-limma.html#notes",
    "href": "log/2025-05-23_prostate-limma.html#notes",
    "title": "Prostate Cancer DEG Analysis (GSE6919)",
    "section": "Notes",
    "text": "Notes\nFull list of gene contribution regulation of angiogenesis STAB1, PAK4, NPR1, PRKD2, SASH1, WNK1, CD40, PDPK1, IL1B, PPP1R16B, HRG regulation of vasculature development\nSTAB1, PAK4, NPR1, PRKD2, SASH1, WNK1, CD40, PDPK1, IL1B, PPP1R16B, HRG positive regulation of angiogenesis PAK4, PRKD2, SASH1, WNK1, CD40, PDPK1, IL1B positive regulation of vasculature development\nPAK4, PRKD2, SASH1, WNK1, CD40, PDPK1, IL1B"
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "Blog",
    "section": "",
    "text": "A collection of occasional deep dives into the tools, topics, and techniques I‚Äôm exploring in bioinformatics, cancer research, and AI."
  },
  {
    "objectID": "blog/index.html#what-i-will-blog",
    "href": "blog/index.html#what-i-will-blog",
    "title": "Blog",
    "section": "",
    "text": "A collection of occasional deep dives into the tools, topics, and techniques I‚Äôm exploring in bioinformatics, cancer research, and AI."
  },
  {
    "objectID": "blog/index.html#recent-posts",
    "href": "blog/index.html#recent-posts",
    "title": "Blog",
    "section": "Recent Posts",
    "text": "Recent Posts"
  },
  {
    "objectID": "blog/C5Biopython.html",
    "href": "blog/C5Biopython.html",
    "title": "Reading the Official Biopython Documentation",
    "section": "",
    "text": "This notebook documents my guided reading of the official Biopython Tutorial & Cookbook.\nFocus: Chapter 5 ‚Äî covering sequence file input/output using SeqIO."
  },
  {
    "objectID": "blog/C5Biopython.html#introduction",
    "href": "blog/C5Biopython.html#introduction",
    "title": "Reading the Official Biopython Documentation",
    "section": "",
    "text": "This notebook documents my guided reading of the official Biopython Tutorial & Cookbook.\nFocus: Chapter 5 ‚Äî covering sequence file input/output using SeqIO."
  },
  {
    "objectID": "blog/C5Biopython.html#chapter-5-sequence-inputoutput-seqio",
    "href": "blog/C5Biopython.html#chapter-5-sequence-inputoutput-seqio",
    "title": "Reading the Official Biopython Documentation",
    "section": "Chapter 5 ‚Äì Sequence Input/Output (SeqIO)",
    "text": "Chapter 5 ‚Äì Sequence Input/Output (SeqIO)\nrecord_iterator = SeqIO.parse(\"ls_orchid.gbk\", \"genbank\")\nfirst_record = next(record_iterator)\nprint(first_record)\nPython supports negative indexing for lists: 0 first element -1 last element -2 second-to-last\nalso useful\nfrom Bio import SeqIO record_iterator = SeqIO.parse(‚Äúls_orchid.gbk‚Äù, ‚Äúgenbank‚Äù) first_record = next(record_iterator) print(first_record)"
  },
  {
    "objectID": "blog/2025-07-24_biopython-reading.html",
    "href": "blog/2025-07-24_biopython-reading.html",
    "title": "Reading C3 of the official Biopython documentation",
    "section": "",
    "text": "This notebook documents my guided reading of the official Biopython Tutorial & Cookbook.\nFocus: Chapter 3 ‚Äî covering the core functionality of working with sequences using Biopython."
  },
  {
    "objectID": "blog/2025-07-24_biopython-reading.html#introduction",
    "href": "blog/2025-07-24_biopython-reading.html#introduction",
    "title": "Reading C3 of the official Biopython documentation",
    "section": "",
    "text": "This notebook documents my guided reading of the official Biopython Tutorial & Cookbook.\nFocus: Chapter 3 ‚Äî covering the core functionality of working with sequences using Biopython."
  },
  {
    "objectID": "blog/2025-07-24_biopython-reading.html#chapter-3-working-with-sequences-seq",
    "href": "blog/2025-07-24_biopython-reading.html#chapter-3-working-with-sequences-seq",
    "title": "Reading C3 of the official Biopython documentation",
    "section": "Chapter 3 ‚Äì Working with Sequences (Seq)",
    "text": "Chapter 3 ‚Äì Working with Sequences (Seq)\nI used this code on day 3 Rosiland problems, link here\ndef reverse_complement(seq):\n    complement = {'A': 'T', 'T': 'A', 'C': 'G', 'G': 'C'}\n    return ''.join(complement[base] for base in reversed(seq))\ninstead i could have used built in biopython function\nprint(s.reverse_complement()) \nBio.SeqUtils has many built in functions such as GC%.\nYou can set reading frames with my_seq[0::3] every 3rd base starting at 0 codon frame 1\nTwo Seq objects can be concatenated by adding them:\nfrom Bio.Seq import Seq\nlist_of_seqs = [Seq(\"ACGT\"), Seq(\"AACC\"), Seq(\"GGTT\")]\nconcatenated = Seq(\"\")\nfor s in list_of_seqs:\n    concatenated += s\n\nconcatenated\nSeq('ACGTAACCGGTT')\nalternatively\nspacer.join(contigs)\nTo make a seq mutable\nfrom Bio.Seq import MutableSeq\nmutable_seq = MutableSeq(my_seq)\nmutable_seq\nMutableSeq('GCCATTGTAATGGGCCGCTGAAAGGGTGCCCGA')\nAn easy way to search a sequence\nfor index, sub in seq.search([\"CC\", \"GGG\", \"CC\"]):\n    print(index, sub)\n\n1 CC\n11 GGG\n14 CC\n23 GGG\n28 CC\n29 CC"
  },
  {
    "objectID": "blog/2025-07-24_biopython-reading.html#chapter-4-sequence-records-seqrecord",
    "href": "blog/2025-07-24_biopython-reading.html#chapter-4-sequence-records-seqrecord",
    "title": "Reading C3 of the official Biopython documentation",
    "section": "Chapter 4 ‚Äì Sequence Records (SeqRecord)",
    "text": "Chapter 4 ‚Äì Sequence Records (SeqRecord)"
  },
  {
    "objectID": "blog/2025-07-24_biopython-reading.html#chapter-5-sequence-inputoutput-seqio",
    "href": "blog/2025-07-24_biopython-reading.html#chapter-5-sequence-inputoutput-seqio",
    "title": "Reading C3 of the official Biopython documentation",
    "section": "Chapter 5 ‚Äì Sequence Input/Output (SeqIO)",
    "text": "Chapter 5 ‚Äì Sequence Input/Output (SeqIO)"
  },
  {
    "objectID": "blog/2025-07-24_biopython-reading.html#chapter-6-sequence-alignments-alignio",
    "href": "blog/2025-07-24_biopython-reading.html#chapter-6-sequence-alignments-alignio",
    "title": "Reading C3 of the official Biopython documentation",
    "section": "Chapter 6 ‚Äì Sequence Alignments (AlignIO)",
    "text": "Chapter 6 ‚Äì Sequence Alignments (AlignIO)"
  },
  {
    "objectID": "blog/2025-05-23_AI in Life Sciences.html",
    "href": "blog/2025-05-23_AI in Life Sciences.html",
    "title": "AI in Life Sciences: What‚Äôs Changing and What‚Äôs Holding Us Back",
    "section": "",
    "text": "This log summarizes key insights from the webinar Inside the Minds of Scientists: How AI is Changing Life Science Research, hosted by Bioinformatics in May 2025.\nüé• Watch the webinar on Vimeo"
  },
  {
    "objectID": "blog/2025-05-23_AI in Life Sciences.html#about",
    "href": "blog/2025-05-23_AI in Life Sciences.html#about",
    "title": "AI in Life Sciences: What‚Äôs Changing and What‚Äôs Holding Us Back",
    "section": "",
    "text": "This log summarizes key insights from the webinar Inside the Minds of Scientists: How AI is Changing Life Science Research, hosted by Bioinformatics in May 2025.\nüé• Watch the webinar on Vimeo"
  },
  {
    "objectID": "blog/2025-05-23_AI in Life Sciences.html#key-trends",
    "href": "blog/2025-05-23_AI in Life Sciences.html#key-trends",
    "title": "AI in Life Sciences: What‚Äôs Changing and What‚Äôs Holding Us Back",
    "section": "Key Trends",
    "text": "Key Trends\n\nAI is moving from discovery to development.\nAI appears to be shifting from predictions to decisions ‚Äî Y Combinator is investing heavily in companies fully run by AI agents.\nPharma is integrating AI across more stages of R&D (e.g., target ID, trial design, decision-making)."
  },
  {
    "objectID": "blog/2025-05-23_AI in Life Sciences.html#whats-holding-ai-back-in-biology",
    "href": "blog/2025-05-23_AI in Life Sciences.html#whats-holding-ai-back-in-biology",
    "title": "AI in Life Sciences: What‚Äôs Changing and What‚Äôs Holding Us Back",
    "section": "What‚Äôs Holding AI Back in Biology?",
    "text": "What‚Äôs Holding AI Back in Biology?\n\nCurrent issues with Ai in biosciences:\n\n\nReproducibility issues ‚Äî hard to trust models without transparent workflows.\nLearning curve and training ‚Äî lack of experience with AI was a significant pain point for many users.\n\nThis resonated with me. I‚Äôve already seen how messy biological data can be, which leads to a steep learning curve and difficulty managing AI outputs."
  },
  {
    "objectID": "blog/2025-05-23_AI in Life Sciences.html#changes-for-future-adoption",
    "href": "blog/2025-05-23_AI in Life Sciences.html#changes-for-future-adoption",
    "title": "AI in Life Sciences: What‚Äôs Changing and What‚Äôs Holding Us Back",
    "section": "Changes for future adoption",
    "text": "Changes for future adoption\n\nTransparency is important for scientists to adopt and understand AI tools ‚Äî they need to know how and what models were trained with.\nTools need to be built with their actual users in mind (biologists)."
  },
  {
    "objectID": "100daysofcode/index.html",
    "href": "100daysofcode/index.html",
    "title": "100 days of code",
    "section": "",
    "text": "a This section is part journal, part learning log. I‚Äôm using the #100DaysOfCode challenge to build consistent coding habits and sharpen my skills. Each entry will either be a quick write-up of what I‚Äôve coded that day, or a summary of something I‚Äôve read or practiced ‚Äî all with a focus on clean, professional documentation."
  },
  {
    "objectID": "100daysofcode/index.html#description",
    "href": "100daysofcode/index.html#description",
    "title": "100 days of code",
    "section": "",
    "text": "a This section is part journal, part learning log. I‚Äôm using the #100DaysOfCode challenge to build consistent coding habits and sharpen my skills. Each entry will either be a quick write-up of what I‚Äôve coded that day, or a summary of something I‚Äôve read or practiced ‚Äî all with a focus on clean, professional documentation."
  },
  {
    "objectID": "100daysofcode/Day8.html",
    "href": "100daysofcode/Day8.html",
    "title": "Day 8: Rosalind Problems ‚Äì Independent Alleles, Protein Motif & Shared Motif",
    "section": "",
    "text": "Compute the probability that at least (N) of the (2^k) offspring have genotype Aa‚ÄØBb, given every parent is Aa‚ÄØBb.\nMy solution\nimport math\n\ndef independent_assortment(k: int, N: int) -&gt; float:\n    \"\"\"\n    P(X ‚â• N) where X ~ Binomial(n = 2**k, p = 1/4).\n    Each of the 2**k offspring has p = 1/4 chance of Aa‚ÄØBb.\n    \"\"\"\n    n = 2**k\n    p = 1/4\n    prob = 0.0\n    # sum the right‚Äêhand tail of the binomial distribution\n    for i in range(N, n+1):\n        prob += math.comb(n, i) * p**i * (1-p)**(n-i)\n    return prob\n\nif __name__ == \"__main__\":\n    k, N = 5, 8\n    print(f\"{independent_assortment(k, N):.6f}\")\n\n\nBinomial ‚Äútail‚Äù sums The probability of getting at least (N) successes out of (n) trials with success rate (p) is \\[\n    P(X \\ge N)\n    \\;=\\;\n    \\sum_{i=N}^{n} \\binom{n}{i}\\,p^i\\,(1-p)^{\\,n-i}\\,.\n  \\] Implemented in Python by summing from i = N to n of math.comb(n, i) * p**i * (1-p)**(n-i).\n\nExact binomial coefficients\nPython¬†3.8+‚Äôs math.comb(n, i) computes () directly and exactly.\nOff‚Äëby‚Äëone vigilance\nTranslating between 0‚Äëbased loops (Python) and 1‚Äëbased math notation (Rosalind) requires adding or subtracting‚ÄØ1 at the right spots."
  },
  {
    "objectID": "100daysofcode/Day8.html#problem-1-independent-alleles",
    "href": "100daysofcode/Day8.html#problem-1-independent-alleles",
    "title": "Day 8: Rosalind Problems ‚Äì Independent Alleles, Protein Motif & Shared Motif",
    "section": "",
    "text": "Compute the probability that at least (N) of the (2^k) offspring have genotype Aa‚ÄØBb, given every parent is Aa‚ÄØBb.\nMy solution\nimport math\n\ndef independent_assortment(k: int, N: int) -&gt; float:\n    \"\"\"\n    P(X ‚â• N) where X ~ Binomial(n = 2**k, p = 1/4).\n    Each of the 2**k offspring has p = 1/4 chance of Aa‚ÄØBb.\n    \"\"\"\n    n = 2**k\n    p = 1/4\n    prob = 0.0\n    # sum the right‚Äêhand tail of the binomial distribution\n    for i in range(N, n+1):\n        prob += math.comb(n, i) * p**i * (1-p)**(n-i)\n    return prob\n\nif __name__ == \"__main__\":\n    k, N = 5, 8\n    print(f\"{independent_assortment(k, N):.6f}\")\n\n\nBinomial ‚Äútail‚Äù sums The probability of getting at least (N) successes out of (n) trials with success rate (p) is \\[\n    P(X \\ge N)\n    \\;=\\;\n    \\sum_{i=N}^{n} \\binom{n}{i}\\,p^i\\,(1-p)^{\\,n-i}\\,.\n  \\] Implemented in Python by summing from i = N to n of math.comb(n, i) * p**i * (1-p)**(n-i).\n\nExact binomial coefficients\nPython¬†3.8+‚Äôs math.comb(n, i) computes () directly and exactly.\nOff‚Äëby‚Äëone vigilance\nTranslating between 0‚Äëbased loops (Python) and 1‚Äëbased math notation (Rosalind) requires adding or subtracting‚ÄØ1 at the right spots."
  },
  {
    "objectID": "100daysofcode/Day8.html#problem-2-finding-a-protein-motif",
    "href": "100daysofcode/Day8.html#problem-2-finding-a-protein-motif",
    "title": "Day 8: Rosalind Problems ‚Äì Independent Alleles, Protein Motif & Shared Motif",
    "section": "Problem 2: Finding a Protein Motif",
    "text": "Problem 2: Finding a Protein Motif\nLocate every occurrence (including overlaps) of the N‚Äëglycosylation motif N{P}[ST]{P} in a set of UniProt sequences.\nMy solution\nfrom Bio import SeqIO\n\ndef get_substrings(s):\n    \"\"\"\n    Generate all possible substrings of the input string s,\n    returning them from longest to shortest.\n\n    Parameters:\n        s (str): The string from which to generate substrings.\n\n    Returns:\n        List[str]: A list of every substring of s, ordered by decreasing length.\n    \"\"\"\n    substrs = []             # Will hold all substrings\n    n = len(s)               # Total length of the string\n\n    # For each possible substring length L from n down to 1\n    for L in range(n, 0, -1):\n        # Slide a window of length L along the string\n        # i goes from 0 up to n - L\n        for i in range(n - L + 1):\n            # Extract the substring of length L starting at i\n            substrs.append(s[i:i + L])\n    return substrs          # Return all substrings, longest first\n\ndef longest_common_substring_bruteforce(records):\n    \"\"\"\n    Find the longest substring common to all sequences in the provided SeqRecord list,\n    using a brute‚Äëforce approach.\n\n    \"\"\"\n    # Convert each SeqRecord to a plain Python string\n    seqs = [str(rec.seq) for rec in records]\n\n    # Sort by length so the shortest sequence is first\n    # We only need to generate substrings from the shortest one\n    seqs.sort(key=len)\n    shortest = seqs[0]       # The sequence to pull substrings from\n    others = seqs[1:]        # The rest of the sequences\n\n    # Generate substrings from longest to shortest\n    for sub in get_substrings(shortest):\n        # Check if this substring appears in every other sequence\n        if all(sub in seq for seq in others):\n            return sub       # As soon as one matches all, it's the LCS\n\n    return \"\"  # If no common substring is found (edge case), return empty\n\n\n\n\nif __name__ == \"__main__\":\n    # Parse the FASTA file (make sure the filename matches exactly)\n    records = list(SeqIO.parse(\"rosalind_lcsm (2).fasta\", \"fasta\"))\n\n    # Compute the longest common substring\n    result = longest_common_substring_bruteforce(records)\n\n    # Output the result\n    print(\"Brute‚Äëforce LCS:\", result)\n\nWhat I learned:\n\nZero‚Äëwidth look‚Äëahead ((?=‚Ä¶)) lets the engine test every offset without skipping‚Äîso overlapping motifs (e.g.¬†positions 276‚ÄØand‚ÄØ278) are both found.\nTranslating PROSITE shorthand (N{P}[ST]{P}) to regex (N[^P][ST][^P]).\nRobust HTTP fetch with raise_for_status() to catch bad accessions early."
  },
  {
    "objectID": "100daysofcode/Day8.html#problem-3-finding-a-shared-motif",
    "href": "100daysofcode/Day8.html#problem-3-finding-a-shared-motif",
    "title": "Day 8: Rosalind Problems ‚Äì Independent Alleles, Protein Motif & Shared Motif",
    "section": "Problem 3: Finding a Shared Motif",
    "text": "Problem 3: Finding a Shared Motif\nIdentify the longest substring common to all sequences in a FASTA file (brute‚Äëforce approach).\nMy solution\nimport re\nimport requests\n\"\"\"\n    this projecct is abandoned, untill further skills are acquired i cannot complete this project yet.\nthis projecct is abandoned, untill further skills are acquired i cannot complete this project yet.\nthis projecct is abandoned, untill further skills are acquired i cannot complete this project yet.\nthis projecct is abandoned, untill further skills are acquired i cannot complete this project yet.\nthis projecct is abandoned, untill further skills are acquired i cannot complete this project yet.\nthis projecct is abandoned, untill further skills are acquired i cannot complete this project yet.\nthis projecct is abandoned, untill further skills are acquired i cannot complete this project yet.\nthis projecct is abandoned, untill further skills are acquired i cannot complete this project yet.\nthis projecct is abandoned, untill further skills are acquired i cannot complete this project yet.\n\n    \"\"\"\n# Compile the PROSITE motif using a look‚Äëahead so we catch overlaps\n# (?=(‚Ä¶)) is zero‚Äëwidth, so the regex engine checks at every position without skipping\nmotif = re.compile(r\"(?=(N[^P][ST][^P]))\")\n\ndef fetch_sequence(accession: str) -&gt; str:\n    \"\"\"\n    Given a UniProt accession (optionally with \"_NAME\" suffix),\n    fetch its protein FASTA from UniProt and return the concatenated sequence.\n    \"\"\"\n    # Strip off anything after the first underscore\n    acc = accession.split(\"_\", 1)[0]\n    url = f\"https://www.uniprot.org/uniprot/{acc}.fasta\"\n    resp = requests.get(url)\n    resp.raise_for_status()\n    lines = resp.text.splitlines()\n    # Skip the header (first line) and join the rest into one sequence string\n    return \"\".join(lines[1:])\n\ndef find_motif_positions(seq: str) -&gt; list[str]:\n    \"\"\"\n    Scan `seq` for the N‚Äëglycosylation motif N{P}[ST]{P},\n    returning all 1‚Äëbased start positions (including overlaps).\n    \"\"\"\n    # m.start() is 0‚Äëbased, so add 1 for Rosalind‚Äôs 1‚Äëbased indexing\n    return [str(m.start() + 1) for m in motif.finditer(seq)]\n\ndef main():\n    # Read your list of raw UniProt IDs (one per line) from ids_mprt.txt\n    with open(\"ids_mprt.txt\") as f:\n        raw_ids = [line.strip() for line in f if line.strip()]\n\n    for raw in raw_ids:\n        seq = fetch_sequence(raw)\n        positions = find_motif_positions(seq)\n        if positions:\n            # Print the original raw ID, then the space‚Äëseparated positions\n            print(raw)\n            print(\" \".join(positions))\n\nif __name__ == \"__main__\":\n    main()\n\nWhat I learned:\n\nSorting by length ensures we find the longest common substring early and exit."
  },
  {
    "objectID": "100daysofcode/Day6.html",
    "href": "100daysofcode/Day6.html",
    "title": "Day 6: Rosalind Problems ‚Äì Mortal Fibonacci & Consensus DNA",
    "section": "",
    "text": "This session tackled two core bioinformatics problems from Rosalind: population modeling with lifespan constraints and nucleotide consensus building across multiple FASTA records."
  },
  {
    "objectID": "100daysofcode/Day6.html#problem-1-mortal-fibonacci-rabbits",
    "href": "100daysofcode/Day6.html#problem-1-mortal-fibonacci-rabbits",
    "title": "Day 6: Rosalind Problems ‚Äì Mortal Fibonacci & Consensus DNA",
    "section": "Problem 1: Mortal Fibonacci Rabbits",
    "text": "Problem 1: Mortal Fibonacci Rabbits\nSimulated rabbit population growth over 89 months with a fixed lifespan of 18 months.\nmy solution\nn = 89  # Total months\nm = 18  # Lifespan in months\n\ndef mortal_fibonacci(n, m):\n    ages = [1] + [0] * (m - 1) # max array length = m\n\n    for month in range(1, n):\n        new_borns = sum(ages[1:])  # rabbits of age ‚â•1 can reproduce\n        # Age rabbits: shift right, oldest dies\n        ages = [new_borns] + ages[:-1]\n\n    return sum(ages)\nprint(mortal_fibonacci(n, m))\n\nWhat I learned:\n\nages[1:] ensures only mature rabbits reproduce.\narrays have an interesting usecase due to its max capacity."
  },
  {
    "objectID": "100daysofcode/Day6.html#problem-2-consensus-and-profile",
    "href": "100daysofcode/Day6.html#problem-2-consensus-and-profile",
    "title": "Day 6: Rosalind Problems ‚Äì Mortal Fibonacci & Consensus DNA",
    "section": "Problem 2: Consensus and Profile",
    "text": "Problem 2: Consensus and Profile\nGiven multiple DNA sequences in FASTA format, construct a profile matrix showing the count of each base at each position, and build a consensus string using the most frequent base at each position. My solution\nfrom Bio import SeqIO\nfrom collections import Counter, defaultdict\n\nrecords = list(SeqIO.parse(\"rosalind_cons1.fasta\", \"fasta\"))\nfull_dna = list(zip(*[str(record.seq) for record in records]))\n\n\nprofile = {\n    'A': [],\n    'C': [],\n    'G': [],\n    'T': []\n}\n\nfor col in full_dna:\n    counts = Counter(col)\n    for base in \"ACGT\":\n        profile[base].append(counts.get(base, 0))\n\nconsensus = \"\"\nfor i in range(len(full_dna)):\n    max_base = max(\"ACGT\", key=lambda base: profile[base][i])\n    consensus += max_base\n\nprint(consensus)\n\nWhat I learned:\n\nzip(*sequences) is a clean Python trick to transpose a matrix (get columns).\nCounter helps efficiently count nucleotides at each position.\nBuilding a consensus string is just choosing the max-count base per column.\nHandling multi-record FASTA files is smoother using SeqIO.parse()."
  },
  {
    "objectID": "100daysofcode/Day4.html",
    "href": "100daysofcode/Day4.html",
    "title": "Day 4: Rosalind Problem ‚Äì Open Reading Frames",
    "section": "",
    "text": "Open Reading Frames (ORF) Identify all distinct protein sequences that can be translated from six possible reading frames of a DNA strand (including its reverse complement). This involves transcribing DNA to RNA, translating in all frames, and extracting sequences that start with a start codon (M) and end at the first stop codon. The solution demonstrates use of Biopython‚Äôs Seq and SeqRecord objects, along with custom logic to capture valid ORFs from both strands.my solution\nfrom Bio import SeqIO\nfrom Bio.Seq import Seq\n\nrecord = SeqIO.read(r\"C:\\Users\\zackd\\Coding challenge\\Day 4 -\\rosalind_orf (2).fasta\", \"fasta\")\n\ndna = record.seq\n# First record is the DNA\nreverse_dna = dna.reverse_complement()\n\n# Transcribe to RNA\nforward_rna = dna.transcribe()\nreverse_rna = reverse_dna.transcribe()\nprint(dna)\n\ndef get_proteins(rna):\n    proteins = set()\n    for frame in range(3):\n        protein = rna[frame:].translate(to_stop=False)\n        aa_seq = str(protein)\n        starts = [i for i in range(len(aa_seq)) if aa_seq[i] == 'M']\n        for start in starts:\n            sub = aa_seq[start:]\n            stop = sub.find(\"*\")\n            if stop != -1:\n                proteins.add(sub[:stop])\n    return proteins\n\n\n\n# Get proteins from all 6 frames\nforward_proteins = get_proteins(forward_rna)\nreverse_proteins = get_proteins(reverse_rna)\n\n# Combine all and print unique\nall_proteins = forward_proteins.union(reverse_proteins)\nprint(\"\\n\".join(all_proteins))\n\n\nThe first half of the challenge was intuative until i arrived at the get proteins function heres my breakdown.\nI couldnt work out the logic for the 3 reading frames\nprotein = rna[frame:].translate(to_stop=False)\nI found similar problem online and this solution works to generate all protein sequences for all frames.\nstarts = [i for i in range(len(aa_seq)) if aa_seq[i] == 'M']\nLoops through my AA string and finds every index where there is a M (start codon)\nThen i looked for all stop codons within the string generated above. now i have M-&gt;*\nfor start in starts:\n    sub = aa_seq[start:]\nThen i removed the stop codon and added it to a protein sequence and returned them\nif stop != -1:\n    proteins.add(sub[:stop])\nMy solution feels abit crude but it works."
  },
  {
    "objectID": "100daysofcode/Day4.html#problem-1-open-reading-frames",
    "href": "100daysofcode/Day4.html#problem-1-open-reading-frames",
    "title": "Day 4: Rosalind Problem ‚Äì Open Reading Frames",
    "section": "",
    "text": "Open Reading Frames (ORF) Identify all distinct protein sequences that can be translated from six possible reading frames of a DNA strand (including its reverse complement). This involves transcribing DNA to RNA, translating in all frames, and extracting sequences that start with a start codon (M) and end at the first stop codon. The solution demonstrates use of Biopython‚Äôs Seq and SeqRecord objects, along with custom logic to capture valid ORFs from both strands.my solution\nfrom Bio import SeqIO\nfrom Bio.Seq import Seq\n\nrecord = SeqIO.read(r\"C:\\Users\\zackd\\Coding challenge\\Day 4 -\\rosalind_orf (2).fasta\", \"fasta\")\n\ndna = record.seq\n# First record is the DNA\nreverse_dna = dna.reverse_complement()\n\n# Transcribe to RNA\nforward_rna = dna.transcribe()\nreverse_rna = reverse_dna.transcribe()\nprint(dna)\n\ndef get_proteins(rna):\n    proteins = set()\n    for frame in range(3):\n        protein = rna[frame:].translate(to_stop=False)\n        aa_seq = str(protein)\n        starts = [i for i in range(len(aa_seq)) if aa_seq[i] == 'M']\n        for start in starts:\n            sub = aa_seq[start:]\n            stop = sub.find(\"*\")\n            if stop != -1:\n                proteins.add(sub[:stop])\n    return proteins\n\n\n\n# Get proteins from all 6 frames\nforward_proteins = get_proteins(forward_rna)\nreverse_proteins = get_proteins(reverse_rna)\n\n# Combine all and print unique\nall_proteins = forward_proteins.union(reverse_proteins)\nprint(\"\\n\".join(all_proteins))\n\n\nThe first half of the challenge was intuative until i arrived at the get proteins function heres my breakdown.\nI couldnt work out the logic for the 3 reading frames\nprotein = rna[frame:].translate(to_stop=False)\nI found similar problem online and this solution works to generate all protein sequences for all frames.\nstarts = [i for i in range(len(aa_seq)) if aa_seq[i] == 'M']\nLoops through my AA string and finds every index where there is a M (start codon)\nThen i looked for all stop codons within the string generated above. now i have M-&gt;*\nfor start in starts:\n    sub = aa_seq[start:]\nThen i removed the stop codon and added it to a protein sequence and returned them\nif stop != -1:\n    proteins.add(sub[:stop])\nMy solution feels abit crude but it works."
  },
  {
    "objectID": "100daysofcode/Day2.html",
    "href": "100daysofcode/Day2.html",
    "title": "Day 1: 4 simple rosiland problems",
    "section": "",
    "text": "Day 2 is a coding warmup Link provided here"
  },
  {
    "objectID": "100daysofcode/Day18.html",
    "href": "100daysofcode/Day18.html",
    "title": "Day 18 ‚Äî ClinVar clustered variants (SQL ‚Üí Python ‚Üí Export)",
    "section": "",
    "text": "Today‚Äôs pipeline (based on my working Python file):\n\nQuery ClinVar (hg19) in BigQuery for pathogenic / likely pathogenic variants\n\nDetect clusters: consecutive variants within MAX_DIST bp (per chromosome)\n\nExport:\n\nclinvar_clustered_pairs_XXXXbp.csv (full table)\nclinvar_rs_batch_XXXXbp.txt (rsIDs for ClinVar batch search)\n\n\nI‚Äôm also collecting reusable lessons so I can copy this approach to other datasets (gnomAD, gene expression, etc)."
  },
  {
    "objectID": "100daysofcode/Day18.html#overview",
    "href": "100daysofcode/Day18.html#overview",
    "title": "Day 18 ‚Äî ClinVar clustered variants (SQL ‚Üí Python ‚Üí Export)",
    "section": "",
    "text": "Today‚Äôs pipeline (based on my working Python file):\n\nQuery ClinVar (hg19) in BigQuery for pathogenic / likely pathogenic variants\n\nDetect clusters: consecutive variants within MAX_DIST bp (per chromosome)\n\nExport:\n\nclinvar_clustered_pairs_XXXXbp.csv (full table)\nclinvar_rs_batch_XXXXbp.txt (rsIDs for ClinVar batch search)\n\n\nI‚Äôm also collecting reusable lessons so I can copy this approach to other datasets (gnomAD, gene expression, etc)."
  },
  {
    "objectID": "100daysofcode/Day18.html#connect-query-your-sql-with-array-safe-bits",
    "href": "100daysofcode/Day18.html#connect-query-your-sql-with-array-safe-bits",
    "title": "Day 18 ‚Äî ClinVar clustered variants (SQL ‚Üí Python ‚Üí Export)",
    "section": "Connect & Query (your SQL, with array-safe bits)",
    "text": "Connect & Query (your SQL, with array-safe bits)\n\nfrom google.cloud import bigquery\nfrom google.oauth2 import service_account\nimport pandas as pd\nimport numpy as np\n\ncreds = service_account.Credentials.from_service_account_file(KEY_PATH)\nclient = bigquery.Client(project=PROJECT_ID, credentials=creds)\n\nchrom_list_sql = \",\".join([f\"'{c}'\" for c in CHROMS])\n\nquery = f\"\"\"\nSELECT\n  reference_name,\n  start_position,\n  end_position,\n  ARRAY_TO_STRING(RS, ',') AS RS,  -- handle ARRAY&lt;STRING&gt; safely\n  GENEINFO,\n  LOWER(sig) AS clnsig\nFROM `{TABLE}`,\nUNNEST(CLNSIG) AS sig\nWHERE reference_name IN ({chrom_list_sql})\n  AND LOWER(sig) LIKE '%pathogenic%'\nORDER BY reference_name, start_position\n\"\"\"\n\nprint(\"Running BigQuery‚Ä¶\")\ndf = client.query(query).to_dataframe()\nprint(f\"Fetched {len(df):,} pathogenic/likely-pathogenic rows.\")\ndf.head()"
  },
  {
    "objectID": "100daysofcode/Day18.html#cluster-detection-consecutive-variants-max_dist",
    "href": "100daysofcode/Day18.html#cluster-detection-consecutive-variants-max_dist",
    "title": "Day 18 ‚Äî ClinVar clustered variants (SQL ‚Üí Python ‚Üí Export)",
    "section": "Cluster Detection (consecutive variants ‚â§ MAX_DIST)",
    "text": "Cluster Detection (consecutive variants ‚â§ MAX_DIST)\ndef parse_geneinfo(x):\n    \"\"\"'BRCA1:672|NBR1:4077' -&gt; ['BRCA1','NBR1']\"\"\"\n    if not isinstance(x, str) or not x:\n        return []\n    return [part.split(\":\")[0] for part in x.split(\"|\") if \":\" in part]\n\npairs_rows = []\nfor chrom, sub in df.groupby(\"reference_name\", sort=False):\n    sub = sub.sort_values(\"start_position\").reset_index(drop=True)\n    pos = sub[\"start_position\"].values\n    for i in range(len(sub) - 1):\n        d = int(pos[i+1] - pos[i])\n        if d &lt;= MAX_DIST:\n            r1 = sub.iloc[i]\n            r2 = sub.iloc[i+1]\n            g1 = parse_geneinfo(r1[\"GENEINFO\"])\n            g2 = parse_geneinfo(r2[\"GENEINFO\"])\n            pairs_rows.append({\n                \"chrom\": chrom,\n                \"pos1\": int(r1[\"start_position\"]),\n                \"pos2\": int(r2[\"start_position\"]),\n                \"distance_bp\": d,\n                \"rs1\": r1[\"RS\"] if r1[\"RS\"] else \"\",\n                \"rs2\": r2[\"RS\"] if r2[\"RS\"] else \"\",\n                \"clnsig1\": r1[\"clnsig\"],\n                \"clnsig2\": r2[\"clnsig\"],\n                \"genes1\": \";\".join(g1),\n                \"genes2\": \";\".join(g2),\n                \"shared_genes\": \";\".join(sorted(set(g1).intersection(g2))),\n            })\n\npairs_df = pd.DataFrame(pairs_rows).sort_values([\"chrom\",\"distance_bp\",\"pos1\"]).reset_index(drop=True)\nprint(f\"Found {len(pairs_df):,} clustered consecutive pairs within {MAX_DIST} bp.\")\npairs_df.head(10)"
  },
  {
    "objectID": "100daysofcode/Day18.html#export-csv-rsids-for-browser-batch-search",
    "href": "100daysofcode/Day18.html#export-csv-rsids-for-browser-batch-search",
    "title": "Day 18 ‚Äî ClinVar clustered variants (SQL ‚Üí Python ‚Üí Export)",
    "section": "Export (CSV + rsIDs for browser batch search)",
    "text": "Export (CSV + rsIDs for browser batch search)\nif not pairs_df.empty:\n    pairs_df.to_csv(CSV_OUT, index=False)\n    print(f\"Saved CSV ‚Üí {CSV_OUT}\")\n\n    rs_ids = pd.unique(pd.concat([pairs_df[\"rs1\"], pairs_df[\"rs2\"]]).dropna())\n    rs_ids = [r for r in rs_ids if isinstance(r, str) and r.startswith(\"rs\")]\n    with open(TXT_OUT, \"w\") as f:\n        f.write(\"\\n\".join(sorted(set(rs_ids), key=lambda x: int(x[2:]) if x[2:].isdigit() else 10**12)))\n    print(f\"Saved RS batch list ‚Üí {TXT_OUT}\")\n\nHow I‚Äôll use it :\n - open the TXT ‚Üí copy all ‚Üí paste into ClinVar‚Äôs search ‚Üí review variant pages & PubMed links."
  },
  {
    "objectID": "100daysofcode/Day18.html#lessons-i-can-reuse-pattern-library",
    "href": "100daysofcode/Day18.html#lessons-i-can-reuse-pattern-library",
    "title": "Day 18 ‚Äî ClinVar clustered variants (SQL ‚Üí Python ‚Üí Export)",
    "section": "Lessons I can reuse (pattern library)",
    "text": "Lessons I can reuse (pattern library)\nSQL patterns\n- Schema-first: inspect table, note array vs scalar fields.\n\n- Array handling: use UNNEST(array) AS alias or convert with ARRAY_TO_STRING(array, ',')\n if I just need a printable value.\n\n- Filter early: push WHERE conditions into SQL so Python handles smaller frames.\nPython patterns\n- Consecutive diffs: sort by position, compare i and i+1 (simple clustering metric).\n\n- Text parsing: split composite fields (GENEINFO) into usable tokens.\n\n- Exports for the web: create both a rich CSV and a plain TXT for batch tools.\nWorkflow patterns\n- Parametrize CHROMS, MAX_DIST, TABLE at the top.\n\n- Keep query ‚Üí process ‚Üí export in separate cells so debugging is easy."
  },
  {
    "objectID": "100daysofcode/Day18.html#how-to-reuse.",
    "href": "100daysofcode/Day18.html#how-to-reuse.",
    "title": "Day 18 ‚Äî ClinVar clustered variants (SQL ‚Üí Python ‚Üí Export)",
    "section": "How to reuse.",
    "text": "How to reuse.\nTo Same query, same clustering, same exports on a different clinvar data set just change table name as all the columns are the same throughout all sets.\nFor local data"
  },
  {
    "objectID": "100daysofcode/Day18.html#key-idea",
    "href": "100daysofcode/Day18.html#key-idea",
    "title": "Day 18 ‚Äî ClinVar clustered variants (SQL ‚Üí Python ‚Üí Export)",
    "section": "key idea",
    "text": "key idea\n1 Pick data source\nfrom google.cloud import bigquery\nfrom google.oauth2 import service_account\n\nPROJECT_ID = \"bio-sql-playground\"\nKEY_PATH   = r\"C:\\Users\\zackd\\Downloads\\bio-sql-playground-bac6463c2d62.json\"\nTABLE      = \"bigquery-public-data.human_variant_annotation.ncbi_clinvar_hg19_20180701\"\n\ncreds  = service_account.Credentials.from_service_account_file(KEY_PATH)\nclient = bigquery.Client(project=PROJECT_ID, credentials=creds)\n2 Flatten arrays early (UNNEST or ARRAY_TO_STRING)\nSELECT\n  reference_name,\n  start_position,\n  end_position,\n  ARRAY_TO_STRING(RS, ',') AS RS,  -- flatten array\n  GENEINFO,\n  LOWER(sig) AS clnsig             -- one label per row\nFROM `bigquery-public-data.human_variant_annotation.ncbi_clinvar_hg19_20180701`,\nUNNEST(CLNSIG) AS sig\n3 Filter early (shrink the dataset in SQL / when loading)\nWHERE reference_name IN ('1','2','‚Ä¶','22','X','Y')\n  AND LOWER(sig) LIKE '%pathogenic%'\nORDER BY reference_name, start_position\n4 Sort = find neighbors (the ‚Äúconsecutive pairs‚Äù trick)\ndef parse_geneinfo(x):\n    if not isinstance(x, str) or not x:\n        return []\n    return [part.split(\":\")[0] for part in x.split(\"|\") if \":\" in part]\n5 Export CSV for analysis\ncsv_path = f\"clinvar_clustered_pairs_{MAX_DIST}bp.csv\"\npairs_df.to_csv(csv_path, index=False)\nprint(\"Saved CSV ‚Üí\", csv_path)"
  },
  {
    "objectID": "100daysofcode/Day3.html",
    "href": "100daysofcode/Day3.html",
    "title": "Day 3: 3 Rosiland problems: FASTA and Biopython",
    "section": "",
    "text": "3 Rosalind Problems ‚Äì FASTA & Biopython A multi-part challenge using Biopython and core Python to solve classic sequence analysis problems:\nLocating Restriction Enzymes ‚Äì Identify reverse palindromic sequences using string manipulation and logic.\nRNA to Protein Translation ‚Äì Convert an RNA sequence into its corresponding protein chain using .translate().\nRNA Splicing ‚Äì Parse multi-record FASTA files, remove introns, and translate the resulting exons into protein.\nThese problems build skill in reading FASTA files, using SeqIO, and applying biological logic to string-based sequence analysis. my solution\ndef reverse_complement(seq):\n    complement = {\"A\": \"T\", \"T\": \"A\", \"C\": \"G\", \"G\": \"C\"}\n    return \"\".join(complement[base] for base in reversed(seq))\n\nfor i in range(len(dna)):\n    for l in range(4, 13):\n        sub = dna[i:i+l]\n        if len(sub) == l and sub == reverse_complement(sub):\n            print(i + 1, l)\n\n\nreversed() - is a clean method to reverse strings.\n.join() - is a clean method to reassemble strings.\nHow to handle variables between biopython to Python."
  },
  {
    "objectID": "100daysofcode/Day3.html#problem-1-locating-restriction-enzymes",
    "href": "100daysofcode/Day3.html#problem-1-locating-restriction-enzymes",
    "title": "Day 3: 3 Rosiland problems: FASTA and Biopython",
    "section": "",
    "text": "3 Rosalind Problems ‚Äì FASTA & Biopython A multi-part challenge using Biopython and core Python to solve classic sequence analysis problems:\nLocating Restriction Enzymes ‚Äì Identify reverse palindromic sequences using string manipulation and logic.\nRNA to Protein Translation ‚Äì Convert an RNA sequence into its corresponding protein chain using .translate().\nRNA Splicing ‚Äì Parse multi-record FASTA files, remove introns, and translate the resulting exons into protein.\nThese problems build skill in reading FASTA files, using SeqIO, and applying biological logic to string-based sequence analysis. my solution\ndef reverse_complement(seq):\n    complement = {\"A\": \"T\", \"T\": \"A\", \"C\": \"G\", \"G\": \"C\"}\n    return \"\".join(complement[base] for base in reversed(seq))\n\nfor i in range(len(dna)):\n    for l in range(4, 13):\n        sub = dna[i:i+l]\n        if len(sub) == l and sub == reverse_complement(sub):\n            print(i + 1, l)\n\n\nreversed() - is a clean method to reverse strings.\n.join() - is a clean method to reassemble strings.\nHow to handle variables between biopython to Python."
  },
  {
    "objectID": "100daysofcode/Day3.html#problem-2-protein-translation",
    "href": "100daysofcode/Day3.html#problem-2-protein-translation",
    "title": "Day 3: 3 Rosiland problems: FASTA and Biopython",
    "section": "Problem 2: Protein Translation",
    "text": "Problem 2: Protein Translation\nmy solution\nfrom Bio.Seq import Seq\n\n\nrna_string = \"AUGCUGUUAUUAAUGUGUAUGUCUUUCCGGGGAGUAAUAACUCAACACAAUCCCUCGGAAGGUUUGCUCAAUUGGAUUCCGUCACAUUCAAGCGCCCGUCUCUCUGCCCUAGUGAUCCUCUUCACAACUUAUACGACGGAGCACUCUGUUCUUGCUGACUUAAUAGAUACCGGAUUAGAGCGUUCCGGUAAGGCUUCGACUCUCUACAUAACGAAGUGCUCUGUCAACUCCAUUAGGCCAUCGGCCGGAUAUCUAGACGCAGACAGCUUUUUCAACUUUGAGGAUCGCGUGAAGGUAUCGACUGCGAACUCUCAUAGGGACUGCUUCCUCUUCGCGGGCAUUUAUCGGGUGAUUUGUGUGGGUAGGGGCCUAAGGAAAGUCACCGGGUCCAUACAGACGGGGGUAUUGAUGAUCUUGCGGGGUGGGUCGGACACCAACAGACCCACCGCGACGGUUCUUCUGAUAUUUGGGCAUUACUUGGGUAGGAGCCCUGUGCUAGUGAAUUGCGCGGCCUUGCAAAUAGCGGCAUGCAACGACACUCUAGGAUUUGAAAACCCCUUUACUCGAGAUAGAACGUCACUAGGCACCACUUAUAAGAUCGGGCGCCGACUUUACGCCUCAUCACCUUUAGUCCGGGAGGCGUACAGCUCACUCCAGGCCUGCGGGAUGGAAACUGGACGUUUCGCUCGGCUGGGCAGAUGUUACGCACGUAGUAGGCUAACGACUUGCUACAAGCAAUACCUCCCAGUGGAAGGCAUUGUUGGGGAAGGCCGCUACGCUGACCUGGGCCGGUAUGUCGGCACGCACCCCGCUAACAGUGUUGUAAAGUAUACUUACCAGCGCGCGCUAGGGCCUCGCCGGGUUGUUCUCAAGGGCCACCAUAGAAAACCCCUUAAUCACGUUACACUAUCUCUCCAUGUGGUCGGUGCGGAGAGGGCGAAGUUAGCCUUGGGCAGGCCCCUUCUGAAUUUUGGCCUCUCGUGGGGGGGUCUAAGAUCUACCUGUAGCACAAUACGAGUAAGCAUCUACCCGUGUGCUGAGAUCCUUGCUAUGCGUCACCCUGUUGCCAACCGAAAAGGGGUGGCAGUUCGAAGGUCGCUGUCAUUGGUGGCUUCCCACCCUCGACCCCCGGUAUAUGCUUUAGUGUCACAGCAAGUAAACUCGCUCGCACCCUAUGCUACAUGCAUCCGCAGGGCAGGACCAUCGAUCGGUCGGGUACGGCAACACAAACUGUCCGGUUAUUUCAGGGAGACACUUAACGCCAGAGCCAUGCCUACGGUUGAGAUAUAUUCCCUGUUGCCCAUGACAGAGUCCAAUGACGCUCACGAGCUAUUUAACCCACGAUCGUAUAGACAAUUUUGGACACCGCGACGAAAUACAUUAUUACGACAAAAGAGUUCGCAAACAAGAUCUAUUACCCAUCUAGGAGUUGGUAUUACUCUUAGCGAGGAGCAACUCUGCAACUUCCCAAGGCAGUAUGAGAUCUCUCUUGUGUUGUGUAGUCUCUUCGAUUUGGCCCGAGAUUCAUGCCAUUCGUACCUGCUUUUCUCCCCCCGGGGUUCCGAACGCGGUAUAGGUGUGUCCUACGUUAGACGGAGGACGCGUCGACACGCUUGGGCCCUGGGUCUGUGUAGGGUAGUCUCGGAGAACAUGAUGAGUUUUAGUAGGCGUGUGCCAUACAAGUUGCUGGAGUUCAAAAGUCGUACGUGCCCUCUAAGCCUUGAGACGCGUCAAACCGUAUUUUACCUGUUUGAAACUUCACUGAAUAACGCUAGAUUUGUGCCUAAUCAUUGGAUAGGGCAGCCUGAGCUCGGCGGCCGGCCCACCAUAGGGGCGGAGACUGGAUGUUCGCAAAUCUUGCGGAGCGGAUCGAAGAUCUAUUAUUGUUAUGAAUUUAGCAAAAUAGGGGCACAAAGCAUCAGUCUUUCCGCACCAGCGAGGGCCAGGAGGUCCUACCAAGGUUGUACUGCUGCACCAGCCUCGUUUGGGAAACCUGGUCAUAAUGUGGCGCGUGGUAAUUACUGGUCUUAUGGGUUAAAGCGGCUGUGCAUCUUCUGGUGGCAGGUGGGACGGCGUAUGGUCAGUCCCUGCCGGCUACUGGAAAUUAUACAAGCUCUAUCUGCAGUCGACAAUCGAGGAAAUCCCGGGAUUCAGUCAGUCUUCGGAUCACAAAGUCGUUGGCUCACAGAACGCGUAGCCAAUAAGCAAGUAAGCAAUCUCGCUCGUGCGGCAGCUAACACCAACCUCGAACCAAACGAAGCCGGGCGGGCAAAACACCGUAAACGUGCUGAUGUCCGGGUUUGCAGAACUGUAGAAAAGCGGGCGAUUUGGCUACUCUUUGGUUUUCAAGAGCUACACUGUCAGGCUUUGGUACAACAGAUCGAGACCGGUUUGCUGAGUUGUAGUGCAUAUAAUAUCCUUGCAACUCCGGAUGUUUCUCGUUUUAUACUUACUAAAAUCCGAUUUGUGAUAUUUCUUAGGGAACCGAAUGUAAUCCGCAGAGAGCAAGCGGGUUUCCUAAUAGAAUCGAAGCCUUCACAGAGGCAAGUCAGUGUGAGUGCCAGGCUGAUAGCUUAUACCACACGCGCACGGUACUACUGCAACAAGUGUGAACCGCAGCCGUGCGCUUAUUCCGAGAUUUCCGCCUGCAUACGCAUCCUUCACGGUUCAAGCGAUCGGCAAUCCUCAGCCAUUACCAACUGUAGGGUCAUGCCGAUCAACAAGAUGGGAAUGACAGGCGCACUGCAUAUGGACGCCUCGUCUCGGCUCUCUAAAACUUGGGAGAGCAGCGAGCGACUAGUAGUGUUCAAUUGUUUCACACGUGGAAGGCUUCCAGGUUGUGCAACUACAAGAUCACGCGAACUUCAUACGAAAAACUCAGCCGCUCUUGAUAAUCUCUUAAUUGUAGGACAGCUUCCCCGAACACAGAGUGGGUGUUAUACGCUCGGCAUUAUGCUUUUCCAAGUCAAGGCGGGGUUCGAAGUUCGCAGCUUAUUGGUUUGGCAAGUUGGUACCAGAGACAAGUUAUCCUCUUCGAGUCACGCCACGGAGGGACAGCCGCUGUUCGAACCUCACCGCCCCGAGCAGCUACACCGAUUACACUCCCGCGAACGGGUGCAAUUCGAUCACGCUACGUACGAUUUCAGCAUACCCGUGUCAGAAACGCUAGACGAAGAUGUUAGUGACCGAGGUCCACGUGACAACAUCAGCGGUUCUAGACCGGUUUCAGCGAUUGUCUUCCCAGCCCCUGGCCCGCAUCGAUGUCUCAUCCAGAGUACGGGCGUAUUUUUGGCGGAGGCAGUGGAACUGGUAAUCUUGCUCGAACCCGCCAGGAUAGACGACCCACAUGAGUUCUACGGGACAUCACCUGGAUUUGGUGAACGUUGUUCGGGGAAAACGGAGUGCUCCGAUCGGCAAGCAUGGCGCGACAUCGAUUUUGGAAUCGAUAUGCUUCUUAUUAGUACCUCAAUAGCGGUGGUGGGUGUAUUGCGUGGACUCACGAACAUGGUGUUGAUUUGGGUGUGGCGCCCACAAACUUAUCAUCCAGCCUUGCAGCUUACUAUUAAGGAGCUAUUUUUCUUCGAUAUUUCAUUUUGCUGGCGGUGCCGGAUAAAUUACGCCAAUGAUGAUACGCAGGGCCGCCAAUAUCGCAGAGCGAGAAUCGCCGACACAUAUGCUAACGUCGCAAUACUAUGUCGUGGAAGCUUCGGCACGCAAAGAACCAGUAUCUAUUCUGCCUGCCCACCAAGGUUCCGCUCCACACUCGGGACCUGUGUUUUUUUUCGGCUCAUGAAAGCAAGCGUUAGACUAGCAAUUACGCUCCGCUCUGUGGCCGACUUUCCGUAUGACGUCCUAAUGACGCCGCAGUAUGAAAAUCUGAACUACUAUCGACUUAAUUCGUCCACAUGCGACCGAGCUCUAGCGAUAUUGAUUGCGAGUCGGCAUAGGGUAUUAGGGAGAUGGUUGUCUUGUCUUGUUCAAUUAGCAAUUUGGUCGGGACGAGAUGAUCACGCACCCUGCUUGAGCCCCCUUAAAUCAAAUUCUCCAUGGCAGAGUCGGAAGGGCUGUAAAAUCGGCCUCGUUUCGGACCAAUGGAAGUUCGAUUUGAGCGCGUCGCGGUAUGCGGGCUGGGACGUCGGCUUCGGUACCUCGAGUAUGAGUGUCGUGUCCCCGUUAAUCACAGGGGUGUAUAAUGCGGAAGCGGCCCAGGGGUACUAUUAUGGGAGCGCCCACGGCUUGAGGGUUCGAGUACUUCUACUCAUGAAGGCUCGCCCUUAUAUAGAGCUAGGCGGUAUGCACCUGAUUAUUGCACACCCGCGAUCAUGUGAGUACAAACCUGUUUUGUGGAAGGUACGCCUUAGGGUUUUCCACCUUUGUGCCUCCCGCUUUGGUCGCGGUCGCGGACCGGUCUUGUCCGGACUUGGUUGUGAGCAGUACAUUUCCGUUUCGCCACCCUUCUUAAACAUACUUUGCAACGCGUCAUGUCCCAACGCCGUACUUAAUAAGCGAGGGGGCUGGAUAUGGUUAUUGGUUCCGUCAACUGUAUCAACCACUACAGUUCCCUAUUUGAAAGUCUCUCUCUCACCAGAAGCUACAGUUUUGCUUUCGGUUGGAACACUGCCCGUUCGCACUGGGGAAAGAGUUAUAUCUUUCUCGGGAUGUAACAUGCAGGUCCUGCCUGCUAAAAAGCUUCGUGUUCUUCUUCCACAUGCACAAACAUGGCUGUGUUAUGUGGAUAAGCUCGCAACUUCACUACGGAGAUGCUACUUCUUCUGUCGAUGUUCGGUAAACGAAGGGGUGAAAAUACUAGAGGUACUAUGCCAACAAUUCACGAUAUGCUUUACAUCGUGCGACCCUAGGAGAGGUCUAGUAGGUAUGACUAUCUUCGAUAAUUUUAGUCAAAUGGUGUUUGGGAAGUCCCAAGGGUGGCAUACGCGUAGUGCCCGGUGUUUAAGCUUGGAAGUCUUGCCCUCUAUGGCGAAACGACUCGUGCACCAGUUUUGGCCCGUUAUGAGUUUUAUUGAUACGCAGAACCGGAUCUGGAUGGGACCCUUAAGCCCGGGGACACGAGCCAGAUGGCUCGGGUUAGCGAAGGCGGAGUGCGUCUCCAGCCCGCCCGCAGCGCCGGCUGUGAAAAAUAAUGUGUGUGAGGUCAUAACUUACGCUGGGGACAAGAACAGUGAUCCAGAACGUACAUCUAACUUUCACAGUGUAGACGCGCUCUGGACAAUGUUCCUUGAUGGUAAUGAUCUAUGGGUGGACUAUAUUAACUGUACGCAGGGCGGAGUGUUAUCUACCAGCCGGACGCGAAUCCCCUCAAACAGGUACACUCGUACUCUAAAACCUUCCCACACGCUCGCCGAGCUUGGUCGUCUCCUUACGUGUGGUCAGACCCGGGGUCCCUUUAAUGCCGUGUCACUAGGCAUGGUUACAGAUUACAGUUACAGUGUCGGUGGAACUUUGGCUUCGAAGCUUGUGACCCUGAGUAUCGCACGCAAUGAUUGUAGCCCUCGUCUGGCACUUUUGUUGCUUAUCGUCCUAAGUAACAUAAUACGAUGUUAUCUCGCUACAUCGUUUUCCGUAUACGCCUUUACAUCAGUAUACUCUGAGCAUUGUCCUGUAAAGAUAGAAGUGUCCAGAUGGGGAGCCGCUCCCAGCAUAAGUUGCUGGCUUUUCGGCGAUGCGCGGAGUGAAUUGGCCCCGGAGAAGAAAACGUUAAUACUGGCACCAGUACCAUACUCUGUUCCACUAGUGGAGGAAUCACGGAAAGGAGAUGGUGGGCAAGGUAUAAGACAGAUCGUAGGUGGCUUCAACAGAUGUUUCCUAGGCACACCGUUUCCACGGGCUGAUAUUGUCAUAAUAGGCAACCCCCAUAUCAGUGACGAACCCCGAGCAUGUAUUUCUUCGAACUUCGUGAGUGAAAUUGUCGUGCAAUAUCACCUACGGUCUAAGUGUUUGAUCCUUGAUGCGAUGAGCACGCCGGGGAAGGCUGGCAAAACAGCUAUAUUUGAGCUGACUAUGUGGCCCUCUCCACUAUCUCAAAUGAGUUUCGCUGCUGGAGCGAAGCGCCGGGGCACGAUCGAUCAUCGCCAACUUCCCUCAAUGCUGGCAGGUGGUAGCCUACUGCGCCAUGUUGGUGUUCGUAACGCACGAGGCUUAUCUCCAGUCAUCAAUCCGCGCCACUAUGGGGCAGGUUUCUCGGACGCUGACGAACAACAGAAACUGGCCAGGACGGGCACUAAGGCCCAGAAUGCAGUGGAUGUUGACGAGCACGGCCCUUCCGCCUUCGCGUUCCCUCUCAUACAGUCGCAGAUCGAGCCCAGGACUCCCAAAUGCUCCGCCGGCAUAGUCUGCAUGAAUGUGCAUUGGAUUACACGGCAUAAGGGACCGUCUUCGGUUCUGUAUAAAAAACACUUGAUGGCUCUGCGCUUCGCCAGCAUUCACUCAGGCAUUCGCAGGAUCUUAGAUCUCCGCUUCUUUAGCACACACCCAGCAAUAAUCUUGACCCGAAAGCAGAUCGAUUCGUCGGUCAUUUCGGUCGCAUGGGCGGCACCAUUGUACUUGUGCAAGAGCAUGCUCUUCCAUGGGGGAAGCGCAUGCGAGCACCGGAAUUGGCACAGGCCUCUCAUAAUCGCAAACUCUAGUCCGGAAUUUAACUUUACCUAUGUGCGGAAAUCUUUGUACCUUGAUUGGCAAAUCCUGUACGUACCGUCGAUAACCCGCCCACCAACCCGAUUUCAGGCCGACCACUUUGAAAGGCCAUGCGUCAACGAUUCGCCGAGGACAUGGCGGGUGAACUCUGGCUGCGGAACGGUAUCACUAGCAGUUCUAAGGCAGGGGACUCUGAAAGCUUAUGGUCGGGUCAGUAGCCGUUCCUCACUUUUAAGGAAUGGGAUAAGUUACACGCCCGUGCAGAAGCAGAUCUGCUCGUCCUUGGCUCGGCGUCCGUACAUGACCGGACGACACCCUACAAGUAGCGUGCUUGUGGGUAGUCAGAAAGGAGUUUGGCGGGGAAGAAGGUCUACCGCGAUGCUGUCGCGAAUGAAGCUAUACGAAUCUACCUCAACGAGAAAACCCGGCUCGUACGGCAAUCUAACUUUUCCCCGAUACUUCUCGCCAUACGGAAGGGAUGGAAGCUUAUGGCAACGCGUUGGAUACGCUGGGCGACCUUUGGGCCGGUCAUUUAACGCCAUCUUAUUUCAACAGACGUUCGUGAAAUUAAUGUCCGAGAGGCUCAAAGGUGAGCAGAAUCCCAGAUCCGGUCUUUGUAUCCUGAUUAAGUCACCACCUGGGGGUACUUACGGUUCUGGUACCUGGGGUAGCUCGCCGACGUGGCGGGAAGUCGGGUGCGUAGGUCUCUUUGCGGUGCGCAGUGAUCCACAUGAGGGUAAACUCCUUAGACAGGUAACCGCACACGGUUCGCUAUGGGGAAAAUCCUGGCCAGUGACUCAUAGUUACGAUGUUUUAGGUCUGGUGGACCUAUUCUCAACUGCUAGAAAGUAUACCACUUAUGACAAUACAGAGGGGAGAUCCCAUCGACCGUCCAGAGAAUUGCUCCCUGAUACUUUCAGAAAACAAGGUGGGAGGUAUCGCGAGGUAGUAUUAUAUCGCACCGUUCGAAUAUGUCAUCUGCUGCCCGUGUCGCAGAUAGCGUCCAGAGCACUGGAACCAUGGAAACUUGUUCCAAAAACGGACAUUAUGUUUUGCGUUUUGGAGCAGGUGAAGCGCAUUAUGCCUACGCCAAGGGCGGCGCGGACAAUUCUGCAAUGUGCCAGUAGCGCGCGGGCUGUGCAGAUUGAGACCGGAUGGGCGGCUCGGUCUCAAGAUGAAGCGGGGACCUUAUUGGACCCAGAUCCAUGUUCGACGCUAGCGAUGACAUGGGUGACGCGGGAAUGGCCGCGGCAGAGCUUGGUCUUCUUGAGACAUGGUUCUGAUCACAUUUGUAGGCAAAAGUAUGCCUGGCUGCAAAACACAAUAUUGUAUUCUGAUAAGGUGGCGGUCAUGCGCCAACUGGGACUUGGGCCGGGAGUCCGACACCCUACUGUCCCCCCGAUACGUGAAAGACACGAAGGACCUAGAUACCGGAGAACAUCACAAAACUCGAUAUUACCGGUUCUUUUGGUUCAUAGCCAGCGUGCGGGGACUCUAAUGUUACUUGACAUAGUGAGUAAAUUGAGCACGAUCAGCGAAGGAAGAGUCCUGAACUGUCGGAACGGUCUAUUGGUGUCCAAUGUGGCCCCCCGACAAACGAUCGCCCUAAAUGAGAGCCAGAAGAGACUGGAUAGUUUCCGACGAAUUAUAUCAUUUACAGUGUUGAGCAACUAUCAUGACUAUUUGCCCUACUAUGGAGAGUCAAGUGGACAAGGCGGAGAGGCCUUAUUUGAUGAGGGCAAACCAGUCCGUAAUACAUUUAAGGAAAGCGCCUUCACGAGCGUGCCUUCAGUAACUUCAGGAUAUGUGGACGUUGACACUGCAAAAAUCAUUGUGUGCCUACUUCGUAUGCCAGUAUAUAUACAAGCCUCUUCAGCGGUGAGGGCUAGCCAGCGGAGUUCUGACGCAAUUACCUACUAG\"\n\n# Convert to Seq object\ndna_seq = Seq(rna_string.replace(\"U\", \"T\"))  # Replace 'U' with 'T' to make it DNA\n\n# Translate\nprotein = dna_seq.translate()\n\n# Output the result\nprint(protein)\n\nWhat i learned:\n.replace(‚ÄúU‚Äù, ‚ÄúT‚Äù) to convert an RNA string into DNA format before translation.\n.translate() - is a clean method to translate DNA into proteins\nBiopython‚Äôs Seq object to translate RNA into protein\nFasta manipulation"
  },
  {
    "objectID": "100daysofcode/Day3.html#problem-3-rna-splicing",
    "href": "100daysofcode/Day3.html#problem-3-rna-splicing",
    "title": "Day 3: 3 Rosiland problems: FASTA and Biopython",
    "section": "Problem 3: RNA Splicing",
    "text": "Problem 3: RNA Splicing\nmy solution\nfrom Bio import SeqIO\nfrom Bio.Seq import Seq\n\n# Load FASTA file\nrecords = list(SeqIO.parse(\"rosalind_splc.fasta\", \"fasta\"))\n\n# First record is the DNA with introns\nfull_dna = str(records[0].seq)\n\n# Remaining records are introns\nintrons = [str(rec.seq) for rec in records[1:]]\n\n# Remove all introns from the full sequence\nfor intron in introns:\n    full_dna = full_dna.replace(intron, \"\")\n\n# Transcribe and translate\nrna = Seq(full_dna).transcribe()\nprotein = rna.translate(to_stop=True)\n\nprint(protein)\n\nWhat i learned:\nSeqIO.parse() - to do FASTA file Parsing\n.replace(intron, ‚Äú‚Äú) - to splice introns\nhow to handle multi-record FASTA files\nLoad Fasta ‚Üí assign parts (.seq biopython) ‚Üí convert to string (str() python) ‚Üí manipulate ‚Üí return"
  },
  {
    "objectID": "100daysofcode/Day5.html",
    "href": "100daysofcode/Day5.html",
    "title": "Day 5: Rosalind Problems ‚Äì GC Content & Hamming Distance",
    "section": "",
    "text": "his post covers four foundational problems from rosiand, exploring GC content, Hamming distance, Mendelian inheritance, and Fibonacci-style recurrence relations. All problems were solved using Biopython"
  },
  {
    "objectID": "100daysofcode/Day5.html#problem-1-gc-content",
    "href": "100daysofcode/Day5.html#problem-1-gc-content",
    "title": "Day 5: Rosalind Problems ‚Äì GC Content & Hamming Distance",
    "section": "Problem 1: GC Content",
    "text": "Problem 1: GC Content\nCalculate the GC content of multiple DNA strings in FASTA format and identify the one with the highest GC percentage.\nMy solution\n#https://rosalind.info/problems/gc/\n\nfrom Bio import SeqIO\nfrom Bio.Seq import Seq\nfrom Bio.SeqUtils import gc_fraction\nimport os\n\n\n# Get directory of the current script\nscript_dir = os.path.dirname(os.path.realpath(__file__))\nfasta_path = os.path.join(script_dir, \"rosalind_gc.fasta\")\nrecords = list(SeqIO.parse(fasta_path, \"fasta\"))\n\n# Track highest GC content and ID\nmax_gc = 0\nmax_id = \"\"\n# Loop over each record and calculate GC content\nfor record in records:\n    gc = gc_fraction(record.seq) * 100  # get % value\n    if gc &gt; max_gc:\n        max_gc = gc\n        max_id = record.id\n\n# Print results\nprint(max_id)\nprint(f\"{max_gc:.6f}\")\n\nWhat I learned:\n\ngc_fraction from Bio.SeqUtils gives clean GC percentages.\nLooping through SeqIO records helps to process multiple sequences efficiently.\nComparing and tracking values is easy using standard if logic"
  },
  {
    "objectID": "100daysofcode/Day5.html#problem-2-hamming-distance",
    "href": "100daysofcode/Day5.html#problem-2-hamming-distance",
    "title": "Day 5: Rosalind Problems ‚Äì GC Content & Hamming Distance",
    "section": "Problem 2: Hamming Distance",
    "text": "Problem 2: Hamming Distance\nCompute the number of differing characters between two DNA strings of equal length.\nMy solution\n# https://rosalind.info/problems/hamm/\n\nfrom Bio import SeqIO\nimport os\n\n\n# Get directory of the current script\nscript_dir = os.path.dirname(os.path.realpath(__file__))\nfasta_path = os.path.join(script_dir, \"rosalind_hamm.fasta\")\nrecords = list(SeqIO.parse(fasta_path, \"fasta\"))\n\nfor i in range(len(records)):\n    for j in range(i + 1, len(records)):\n        # Calculate Hamming distance\n        seq1 = records[i].seq\n        seq2 = records[j].seq\n        hamming_distance = sum(el1 != el2 for el1, el2 in zip(seq1, seq2))\n        print(hamming_distance)\n\nWhat I learned:\n\nzip(seq1, seq2) lets you pair corresponding elements.\nThe comparison el1 != el2 returns True for mismatches (which equals 1 when summed).\nsum(...) neatly counts total differences without explicit loops."
  },
  {
    "objectID": "100daysofcode/Day5.html#problem-3-hamming-distance",
    "href": "100daysofcode/Day5.html#problem-3-hamming-distance",
    "title": "Day 5: Rosalind Problems ‚Äì GC Content & Hamming Distance",
    "section": "Problem 3: Hamming Distance",
    "text": "Problem 3: Hamming Distance\nGiven the number of homozygous dominant (AA), heterozygous (Aa), and homozygous recessive (aa) individuals in a population, compute the probability that two randomly selected mating organisms will produce an individual possessing a dominant allele.\nMy solution\n# https://rosalind.info/problems/iprb/\nAApop = 29\nAapop = 17\naapop = 22\n\ntotalpop = AApop + Aapop + aapop\n\n#                             aA                                          AA                                                 aa                                                   Aa\naaoutcome = ((aapop/totalpop) * ((Aapop)/(totalpop-1))*0.5) + ((Aapop/totalpop) * ((Aapop-1)/(totalpop-1))*0.25) + ((aapop/totalpop) * ((aapop-1)/(totalpop-1))) + ((Aapop/totalpop) * ((aapop)/(totalpop-1))*0.5)\n\n\n\n\nAoutcome = (1 - aaoutcome) * 100\n\n\nprint(f\"{Aoutcome:.2f}% of the offspring will have a dominant allele\")\n\nWhat I learned:\n\nProbability trees help remove errors.\nThe cleanest solution subtracts P(recessive) from 1 to get P(dominant)"
  },
  {
    "objectID": "100daysofcode/Day5.html#problem-3-rabbits-and-recurrence-relations",
    "href": "100daysofcode/Day5.html#problem-3-rabbits-and-recurrence-relations",
    "title": "Day 5: Rosalind Problems ‚Äì GC Content & Hamming Distance",
    "section": "Problem 3: Rabbits and Recurrence Relations",
    "text": "Problem 3: Rabbits and Recurrence Relations\nMy solution\nmonths = 36\nlitter_size = 2\n\nprev = 1  # F(n-2)\ncurr = 1  # F(n-1)\n\nfor _ in range(3, months + 1):\n    next_rabbits = curr + litter_size * prev\n    prev, curr = curr, next_rabbits\n\nprint(months, curr)\n#curr = number of pairs last month (F(n‚àí1)).\n#prev = number of pairs two months ago (F(n‚àí2)).\n\nWhat I learned:\n\nClean recurrence: F(n) = F(n‚àí1) + k * F(n‚àí2)."
  },
  {
    "objectID": "100daysofcode/Day7.html",
    "href": "100daysofcode/Day7.html",
    "title": "Day 7: Rosalind Problems ‚Äì Overlap Graphs &",
    "section": "",
    "text": "Given a collection of DNA strings in FASTA format, construct the overlap graph where each edge represents a suffix-prefix match of length k.\nMy solution\nfrom Bio import SeqIO\n\nk = 3\nrecords = list(SeqIO.parse(\"rosalind_grph (1).fasta\", \"fasta\"))\nfor record in records:\n    record_suffix = str(record.seq)[-k:]\n    for other_record in records:\n        if record.id == other_record.id:\n            continue\n        other_prefix = str(other_record.seq)[:k]\n        if record_suffix == other_prefix:\n            print(record.id, other_record.id)\n\n\n\nOverlap graphs are generated by comparing the last k bases of one sequence to the first k of another.\nUse of continue avoids redundant self-comparisons.\nstr(record.seq) converts Biopython Seq objects for string slicing."
  },
  {
    "objectID": "100daysofcode/Day7.html#problem-1-overlap-graphs",
    "href": "100daysofcode/Day7.html#problem-1-overlap-graphs",
    "title": "Day 7: Rosalind Problems ‚Äì Overlap Graphs &",
    "section": "",
    "text": "Given a collection of DNA strings in FASTA format, construct the overlap graph where each edge represents a suffix-prefix match of length k.\nMy solution\nfrom Bio import SeqIO\n\nk = 3\nrecords = list(SeqIO.parse(\"rosalind_grph (1).fasta\", \"fasta\"))\nfor record in records:\n    record_suffix = str(record.seq)[-k:]\n    for other_record in records:\n        if record.id == other_record.id:\n            continue\n        other_prefix = str(other_record.seq)[:k]\n        if record_suffix == other_prefix:\n            print(record.id, other_record.id)\n\n\n\nOverlap graphs are generated by comparing the last k bases of one sequence to the first k of another.\nUse of continue avoids redundant self-comparisons.\nstr(record.seq) converts Biopython Seq objects for string slicing."
  },
  {
    "objectID": "100daysofcode/Day7.html#problem-2-mortal-fibonacci-rabbits",
    "href": "100daysofcode/Day7.html#problem-2-mortal-fibonacci-rabbits",
    "title": "Day 7: Rosalind Problems ‚Äì Overlap Graphs &",
    "section": "Problem 2: Mortal Fibonacci Rabbits",
    "text": "Problem 2: Mortal Fibonacci Rabbits\nMy solution\ncounts = [1, 0, 0, 1, 0, 1]\nweights = [1.0, 1.0, 1.0, 0.75, 0.5, 0.0]\n\nexpected_dominant_offspring = sum(2 * count * prob for count, prob in zip(counts, weights))\nprint(expected_dominant_offspring)\n\nWhat I learned:\n\nzip(counts, weights) combines both lists for pairwise computation in the list comprehension."
  },
  {
    "objectID": "100daysofcode/Day9.html",
    "href": "100daysofcode/Day9.html",
    "title": "Day 9: Rosalind Problems ‚Äì Enumerating Gene Orders,Synteny Blocks Have Orientations",
    "section": "",
    "text": "Given: A positive integer (n ).\nReturn: First, the total number of permutations of length (n). Then list every permutation of ({1,2,,n}) (in any order), one per line.\n\nMy solution\nfrom itertools import permutations\nimport math\n\ndef main():\n    n = 5\n    # Print the total number of permutations (n!)\n    print(math.factorial(n))\n    # Generate and print each permutation of 1..n\n    with open(\"rosalind_perm.txt\", \"w\") as f:\n        for perm in permutations(range(1, n+1)):\n            f.write(\" \".join(map(str, perm)) + \"\\n\")\n    print(f\"All {math.factorial(n)} permutations written to {'rosalind_perm.txt'}\")\n\n\nif __name__ == \"__main__\":\n    main()\n\n\n\nTotal count A permutation of length (n) is an ordering of ({1,,n}). There are [ n! = 1 n ] such orderings.\nGeneration strategy\n\nBuilt-in: Python‚Äôs itertools.permutations returns all (n!) tuples.\nRecursive: Fix each element in turn at the front, recurse on the remaining (n-1)."
  },
  {
    "objectID": "100daysofcode/Day9.html#problem-1-enumerating-gene-orders",
    "href": "100daysofcode/Day9.html#problem-1-enumerating-gene-orders",
    "title": "Day 9: Rosalind Problems ‚Äì Enumerating Gene Orders,Synteny Blocks Have Orientations",
    "section": "",
    "text": "Given: A positive integer (n ).\nReturn: First, the total number of permutations of length (n). Then list every permutation of ({1,2,,n}) (in any order), one per line.\n\nMy solution\nfrom itertools import permutations\nimport math\n\ndef main():\n    n = 5\n    # Print the total number of permutations (n!)\n    print(math.factorial(n))\n    # Generate and print each permutation of 1..n\n    with open(\"rosalind_perm.txt\", \"w\") as f:\n        for perm in permutations(range(1, n+1)):\n            f.write(\" \".join(map(str, perm)) + \"\\n\")\n    print(f\"All {math.factorial(n)} permutations written to {'rosalind_perm.txt'}\")\n\n\nif __name__ == \"__main__\":\n    main()\n\n\n\nTotal count A permutation of length (n) is an ordering of ({1,,n}). There are [ n! = 1 n ] such orderings.\nGeneration strategy\n\nBuilt-in: Python‚Äôs itertools.permutations returns all (n!) tuples.\nRecursive: Fix each element in turn at the front, recurse on the remaining (n-1)."
  },
  {
    "objectID": "100daysofcode/Day9.html#problem-2-synteny-blocks-have-orientations-signed-permutationshttpsrosalind.infoproblemssign",
    "href": "100daysofcode/Day9.html#problem-2-synteny-blocks-have-orientations-signed-permutationshttpsrosalind.infoproblemssign",
    "title": "Day 9: Rosalind Problems ‚Äì Enumerating Gene Orders,Synteny Blocks Have Orientations",
    "section": "Problem 2: [Synteny Blocks Have Orientations] (Signed Permutations)(https://rosalind.info/problems/sign/)",
    "text": "Problem 2: [Synteny Blocks Have Orientations] (Signed Permutations)(https://rosalind.info/problems/sign/)\n\nGiven: A positive integer (n ).\nReturn: First, the total number of permutations of length (n). Then list every permutation of ({1,2,,n}) (in any order), one per line.\n\nMy solution\n\nimport itertools  # for generating permutations and all sign combinations\nimport math\n\n\"\"\" Core analogy: signed permutations are like an onion.\n# - The outer layer is the ordering (permutation) of the numbers.\n# - The inner layers are the signs applied to each position (¬±) for that ordering.\n# Peel one layer at a time: fix an ordering, then explore all sign combinations beneath it.\n\"\"\"\ndef main():\n    n = 3  # length of the base permutation (1..n)\n    numbers = list(range(1, n + 1))  # [1, 2, ..., n]\n    output_path = \"signed_permutations.txt\"  # output file for results\n\n    # Open the file once for writing; the 'with' ensures it closes automatically\n    with open(output_path, \"w\") as f:\n        # Compute total number of signed permutations:\n        # n! permutations times 2^n choices of sign assignments\n        total = math.factorial(n) * (2 ** n)\n        f.write(f\"{total}\\n\")  # write the count on the first line\n\n        # Outer loop: iterate over all orderings of [1..n] (the outer onion layer)\n        for perm in itertools.permutations(numbers):  # all orderings (n! of them)\n            # Inner loop: for each ordering, apply every combination of +/‚àí to each position\n            for sign_choice in itertools.product([1, -1], repeat=n):  # 2^n sign vectors\n                # Apply sign to each element of the permutation (elementwise multiplication)\n                signed_perm = [sign_choice[i] * perm[i] for i in range(n)]\n                # Format the signed permutation: include '+' explicitly for positives\n                line = \" \".join(f\"{'+' if x &gt; 0 else ''}{x}\" for x in signed_perm)\n                f.write(line + \"\\n\")  # write one signed permutation per line\n\n    # Confirmation output to console\n    print(f\"Wrote {total} signed permutations to {output_path}\")\n\n# Immediately invoke main when script runs\nmain()\n\nWhat I learned:\n\nSigned permutations structure: n!x2^n = Total permutations = n! independent sign flips = 2^n\nAnalogy (onion): Fix a permutation (outer layer), then peel through all sign combinations underneath.\nFormatting: Explicitly include ‚Äú+‚Äù for positive values to make orientation clear.\nuse of intertools"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "blog/2025-06-11_Crispr.html",
    "href": "blog/2025-06-11_Crispr.html",
    "title": "Engineering to improve the precision and flexibility of crispr editing",
    "section": "",
    "text": "This log summarizes key insights from the webinar The Future of CRISPR, hosted by The Scientist in June 2025.\nWatch the webinar\nIn this blog im going talk about Ben Kleinstivers contribution as it is the most interesting to me."
  },
  {
    "objectID": "blog/2025-06-11_Crispr.html#about",
    "href": "blog/2025-06-11_Crispr.html#about",
    "title": "Engineering to improve the precision and flexibility of crispr editing",
    "section": "",
    "text": "This log summarizes key insights from the webinar The Future of CRISPR, hosted by The Scientist in June 2025.\nWatch the webinar\nIn this blog im going talk about Ben Kleinstivers contribution as it is the most interesting to me."
  },
  {
    "objectID": "blog/2025-06-11_Crispr.html#background",
    "href": "blog/2025-06-11_Crispr.html#background",
    "title": "Engineering to improve the precision and flexibility of crispr editing",
    "section": "Background",
    "text": "Background\n\nCas9 is bacteria‚Äôs adaptive defense against Bacteriophages and cleaves invading DNA strands\nCas9 can only bind and cut DNA at sites adjacent to a PAM sequence.\nWild-type enzymes are naturally occurring enzymes"
  },
  {
    "objectID": "blog/2025-06-11_Crispr.html#what-they-created-httpspammla.streamlit.app",
    "href": "blog/2025-06-11_Crispr.html#what-they-created-httpspammla.streamlit.app",
    "title": "Engineering to improve the precision and flexibility of crispr editing",
    "section": "What they created https://pammla.streamlit.app/",
    "text": "What they created https://pammla.streamlit.app/\n\nPAMmlla is a ML tool that predicts which Cas9 variant is optimal for that sequence‚Äôs PAM recognition to minimize off target activation.\nThey trained PAMmla on a library of cas9 proteins with 6 altered proteins. Expressed them in bacteria and created a selective pressure that required a specific SpCas9 against 1 of 16 different PAMS\nThey then Sequenced the specific domains, And expressed its biological activity against each AA sequence.\nThis was the data that PAMmla was trained on."
  },
  {
    "objectID": "blog/2025-06-11_Crispr.html#significance",
    "href": "blog/2025-06-11_Crispr.html#significance",
    "title": "Engineering to improve the precision and flexibility of crispr editing",
    "section": "Significance",
    "text": "Significance\n\nPAMla has enabled gene editing into previously inaccessible regions of the genome, and reduces trial-and-error in therapeutic development."
  },
  {
    "objectID": "blog/2025-06-11_Crispr.html#questions",
    "href": "blog/2025-06-11_Crispr.html#questions",
    "title": "Engineering to improve the precision and flexibility of crispr editing",
    "section": "Questions",
    "text": "Questions\n\nI wonder if this technology could be used within oncology on multiple gene targets to design combinatorial editing strategies."
  },
  {
    "objectID": "blog/C4Biopython.html",
    "href": "blog/C4Biopython.html",
    "title": "Reading C4 of the Official Biopython Documentation",
    "section": "",
    "text": "This notebook documents my guided reading of the official Biopython Tutorial & Cookbook.\nFocus: Chapter 4 ‚Äî covering the core functionality of working with annotated sequence records using SeqRecord."
  },
  {
    "objectID": "blog/C4Biopython.html#introduction",
    "href": "blog/C4Biopython.html#introduction",
    "title": "Reading C4 of the Official Biopython Documentation",
    "section": "",
    "text": "This notebook documents my guided reading of the official Biopython Tutorial & Cookbook.\nFocus: Chapter 4 ‚Äî covering the core functionality of working with annotated sequence records using SeqRecord."
  },
  {
    "objectID": "blog/C4Biopython.html#chapter-4-sequence-records-seqrecord",
    "href": "blog/C4Biopython.html#chapter-4-sequence-records-seqrecord",
    "title": "Reading C4 of the Official Biopython Documentation",
    "section": "Chapter 4 ‚Äì Sequence Records (SeqRecord)",
    "text": "Chapter 4 ‚Äì Sequence Records (SeqRecord)\nyou can interact with meta data using\nfrom Bio.SeqRecord import SeqRecord\n\nsimple_seq_r.id = \"AC12345\"\nsimple_seq_r.description = \"Made up sequence I wish I could write a paper about\"\nprint(simple_seq_r.description)\nannotations. is used for any miscellaneous annotations\nfrom Bio import SeqIO record = SeqIO.read(‚ÄúNC_005816.fna‚Äù, ‚Äúfasta‚Äù) record.description ‚Äògi|45478711|ref|NC_005816.1| Yersinia pestis biovar Microtus str. 91001 plasmid pPCP1, complete sequence‚Äô\nfeature positions within biopython have a few options,\n\nExactPosition as described\nBeforePosition a range of bases before a feature\nWithinPosition between two specified nucleotides\nOneOfPosition one of 2 exact positions\nUnknownPosition as described\n\nLocation testing for SNPs\nfrom Bio import SeqIO\nmy_snp = 4350\nrecord = SeqIO.read(\"NC_005816.gb\", \"genbank\")\nfor feature in record.features:\n    if my_snp in feature:\n        print(\"%s %s\" % (feature.type, feature.qualifiers.get(\"db_xref\")))\n\nsource ['taxon:229193']\ngene ['GeneID:2767712']\nCDS ['GI:45478716', 'GeneID:2767712']\nfrom Bio.Seq import Seq from Bio.SeqRecord import SeqRecord record = SeqRecord( Seq( ‚ÄúMMYQQGCFAGGTVLRLAKDLAENNRGARVLVVCSEITAVTFRGPSETHLDSMVGQALFGD‚Äù ‚ÄúGAGAVIVGSDPDLSVERPLYELVWTGATLLPDSEGAIDGHLREVGLTFHLLKDVPGLISK‚Äù ‚ÄúNIEKSLKEAFTPLGISDWNSTFWIAHPGGPAILDQVEAKLGLKEEKMRATREVLSEYGNM‚Äù ‚ÄúSSAC‚Äù ), id=‚Äúgi|14150838|gb|AAK54648.1|AF376133_1‚Äù, description=‚Äúchalcone synthase [Cucumis sativus]‚Äù, ) print(record.format(‚Äúfasta‚Äù))"
  },
  {
    "objectID": "blog/C6Biopython.html",
    "href": "blog/C6Biopython.html",
    "title": "Reading the Official Biopython Documentation",
    "section": "",
    "text": "This notebook documents my guided reading of the official Biopython Tutorial & Cookbook.\nFocus: Chapter 6 ‚Äî a preview of handling multiple sequence alignments using AlignIO."
  },
  {
    "objectID": "blog/C6Biopython.html#introduction",
    "href": "blog/C6Biopython.html#introduction",
    "title": "Reading the Official Biopython Documentation",
    "section": "",
    "text": "This notebook documents my guided reading of the official Biopython Tutorial & Cookbook.\nFocus: Chapter 6 ‚Äî a preview of handling multiple sequence alignments using AlignIO."
  },
  {
    "objectID": "blog/C6Biopython.html#chapter-6-sequence-alignments-alignio",
    "href": "blog/C6Biopython.html#chapter-6-sequence-alignments-alignio",
    "title": "Reading the Official Biopython Documentation",
    "section": "Chapter 6 ‚Äì Sequence Alignments (AlignIO)",
    "text": "Chapter 6 ‚Äì Sequence Alignments (AlignIO)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ZackBioData",
    "section": "",
    "text": "üîó Logbook ‚Äî Casual notes, ideas, and progress from daily work and study\nüîó Blog ‚Äî Occasional deeper dives into tools, projects, or topics I‚Äôm exploring\nüîó Daily Coding ‚Äî A dedicated journey to improve coding skills every day for 100 consecutive days\n\n\n\nLanguages & Libraries:\nPython ¬∑ pandas ¬∑ matplotlib ¬∑ Biopython ¬∑ scikit-learn ¬∑ GSEApy ¬∑ Enrichr ¬∑ ClinVar\nComfortable with:\nTranscriptomics ¬∑ Variant filtering ¬∑ Gene expression analysis\nLearning next:\nSequence alignment ¬∑ SnpEff ¬∑ VEP ¬∑ Pathway prediction"
  },
  {
    "objectID": "index.html#what-im-working-with",
    "href": "index.html#what-im-working-with",
    "title": "ZackBioData",
    "section": "",
    "text": "Languages & Libraries:\nPython ¬∑ pandas ¬∑ matplotlib ¬∑ Biopython ¬∑ scikit-learn ¬∑ GSEApy ¬∑ Enrichr ¬∑ ClinVar\nComfortable with:\nTranscriptomics ¬∑ Variant filtering ¬∑ Gene expression analysis\nLearning next:\nSequence alignment ¬∑ SnpEff ¬∑ VEP ¬∑ Pathway prediction"
  },
  {
    "objectID": "log/2025-08-04_MPb-geneticvariants.html",
    "href": "log/2025-08-04_MPb-geneticvariants.html",
    "title": "Variant Filtering in Calcium-Regulating Genes",
    "section": "",
    "text": "The goal of this mini-project is to identify genetic variants that might impair calcium-buffering capacity in cancer cells specifically those that could make them more vulnerable to calcium overload triggered by Mastoparan B.\nMastoparan B is known to destabilise the plasma membrane, leading to a spike in intracellular calcium. If certain genes responsible for calcium homeostasis (e.g.¬†PCP4, ATP2B1, BCL2) are disrupted by mutations, it could tip the balance and push the cell toward apoptosis.\nThis is an early-stage exploration of that hypothesis."
  },
  {
    "objectID": "log/2025-08-04_MPb-geneticvariants.html#project-summary",
    "href": "log/2025-08-04_MPb-geneticvariants.html#project-summary",
    "title": "Variant Filtering in Calcium-Regulating Genes",
    "section": "",
    "text": "The goal of this mini-project is to identify genetic variants that might impair calcium-buffering capacity in cancer cells specifically those that could make them more vulnerable to calcium overload triggered by Mastoparan B.\nMastoparan B is known to destabilise the plasma membrane, leading to a spike in intracellular calcium. If certain genes responsible for calcium homeostasis (e.g.¬†PCP4, ATP2B1, BCL2) are disrupted by mutations, it could tip the balance and push the cell toward apoptosis.\nThis is an early-stage exploration of that hypothesis."
  },
  {
    "objectID": "log/2025-08-04_MPb-geneticvariants.html#methods-overview",
    "href": "log/2025-08-04_MPb-geneticvariants.html#methods-overview",
    "title": "Variant Filtering in Calcium-Regulating Genes",
    "section": "Methods Overview",
    "text": "Methods Overview\n\nInput: Local ClinVar VCF file (clinvar.vcf)\nApproach: String filter by GENEINFO for genes of interest\nLanguages: Python 3.11, basic file handling\nGoal: Print out pathogenic or reviewed variants in relevant calcium-buffering genes\n\n\nGene panel (early draft)\n\nPCP4 ‚Äî Calmodulin modulator, neuron-like buffering\nATP2B1 ‚Äî PMCA1 calcium efflux pump\nBCL2 ‚Äî Anti-apoptotic, links calcium and mitochondrial integrity\nVDAC1 ‚Äî Mitochondrial membrane permeability\nRYR1 ‚Äî Ryanodine receptor; ER calcium release\nMYC - Regulator of glycolysis - drives warburg phenotype"
  },
  {
    "objectID": "log/2025-08-04_MPb-geneticvariants.html#code-snippet",
    "href": "log/2025-08-04_MPb-geneticvariants.html#code-snippet",
    "title": "Variant Filtering in Calcium-Regulating Genes",
    "section": "Code Snippet",
    "text": "Code Snippet\noutput_path = \"mastoparan_variants.txt\"\nout = open(output_path, \"w\", encoding=\"utf-8\")\n\nwith open(r\"C:\\Users\\zackd\\Bioinformatics\\clinvar.vcf\", \"r\") as f:\n    genes_of_interest = [\"PCP4\", \"BCL2\", \"ATP2B1\", \"VDAC1\", \"RYR1\"]\n\n    for line in f:\n        if line.startswith(\"#\"):\n            continue\n\n        cols = line.strip().split(\"\\t\")\n        chrom = cols[0].replace(\"chr\", \"\")\n        pos = int(cols[1])\n        ref = cols[3]\n        alt = cols[4]\n        info = cols[7]\n\n        for gene in genes_of_interest:\n            if f\"GENEINFO={gene}\" in info:\n                info_dict = dict(item.split(\"=\") for item in info.split(\";\") if \"=\" in item)\n                significance = info_dict.get(\"CLNSIG\", \"NA\")\n                disease = info_dict.get(\"CLNDN\", \"NA\")\n                review = info_dict.get(\"CLNREVSTAT\", \"NA\")\n\n                out.write(f\"{chrom}:{pos} {ref}&gt;{alt}\\n\")\n                out.write(f\"   Significance: {significance}\\n\")\n                out.write(f\"   Disease: {disease}\\n\")\n                out.write(f\"   Review: {review}\\n\\n\")\n\nout.close()\n##Output Example\n1:161284466 G&gt;A\n   Gene: PCP4\n   Significance: Benign\n   Disease: not_provided\n   Review: criteria_provided,_multiple_submitters,_no_conflicts\n\n2:111123784 C&gt;T\n   Gene: BCL2\n   Significance: Benign\n   Disease: not_provided\n   Review: criteria_provided,_multiple_submitters,_no_conflicts\nCurrent outputs only provides unreviewed untilted point mutations.\n##Interpretation and Context\nRight now the code just checks if any known variant touches one of the genes above. It doesn‚Äôt check where in the protein the variant lands (e.g.¬†domain, exon, transmembrane), nor does it interpret the functional consequence. But it‚Äôs a good starting point.\nVariants in calcium-buffering genes might:\nReduce calcium export or sequestration\nIncrease membrane fragility or ER stress\nAccelerate the death response after a calcium spike\nThis could improve Mastoparan B‚Äôs selective cytotoxicity via triggering calcium overload, so any inherent loss-of-buffering could be a weak spot.\n##Limitations + Future Add-ons\n\nNo frame shift or missense classification yet\nDoesn‚Äôt look at protein domains (e.g.¬†calmodulin-binding)\nNo integration with ENSEMBL VEP or SnpEff\nNo filtering by ClinVar significance beyond string match\nAdd more genes resulting in warburg effect\n\n##What i learned\n\nFirst interactions with clinvar\nGENEINFO filtering is a quick but rough approach"
  },
  {
    "objectID": "100daysofcode/Day16.html",
    "href": "100daysofcode/Day16.html",
    "title": "Day 16: LeetCode ‚Äì Stock, Parentheses, Palindrome, Duplicates, Sliding Window",
    "section": "",
    "text": "Link: https://leetcode.com/problems/best-time-to-buy-and-sell-stock/\nTask: Return the max profit from one buy and one sell (sell after buy).\nApproach (One-pass): Track the minimum price so far and update best profit with price - min_price.\nclass Solution:\n    def maxProfit(self, prices):\n        if not prices:\n            return 0\n        min_price = prices[0]\n        best = 0\n        for p in prices[1:]:\n            if p - min_price &gt; best:\n                best = p - min_price\n            if p &lt; min_price:\n                min_price = p\n        return best\n\n\n\nWhy one-pass works (buy day always ‚â§ sell day).\nSentinel vs first-element init for running minimum.\nEdge case: strictly decreasing prices ‚Üí 0."
  },
  {
    "objectID": "100daysofcode/Day16.html#what-i-learned",
    "href": "100daysofcode/Day16.html#what-i-learned",
    "title": "Day 16: LeetCode ‚Äì Stock, Parentheses, Palindrome, Duplicates, Sliding Window",
    "section": "",
    "text": "Why one-pass works (buy day always ‚â§ sell day).\nSentinel vs first-element init for running minimum.\nEdge case: strictly decreasing prices ‚Üí 0."
  },
  {
    "objectID": "100daysofcode/Day16.html#what-i-learned-1",
    "href": "100daysofcode/Day16.html#what-i-learned-1",
    "title": "Day 16: LeetCode ‚Äì Stock, Parentheses, Palindrome, Duplicates, Sliding Window",
    "section": "what i learned",
    "text": "what i learned\n\nClassic stack usage; LIFO ensures nearest unmatched open closes first.\nEarly exits on mismatch or premature close."
  },
  {
    "objectID": "100daysofcode/Day16.html#what-i-learned-2",
    "href": "100daysofcode/Day16.html#what-i-learned-2",
    "title": "Day 16: LeetCode ‚Äì Stock, Parentheses, Palindrome, Duplicates, Sliding Window",
    "section": "what i learned",
    "text": "what i learned\n\nSkipping non-alnum in-place avoids extra space.\n.lower() is usually fine; .casefold() is stricter for Unicode.\n.isalnum() keep only letters/digits before comparing. - strip punctuation"
  },
  {
    "objectID": "100daysofcode/Day16.html#what-i-learned-3",
    "href": "100daysofcode/Day16.html#what-i-learned-3",
    "title": "Day 16: LeetCode ‚Äì Stock, Parentheses, Palindrome, Duplicates, Sliding Window",
    "section": "what i learned",
    "text": "what i learned\n\nSet membership is average O(1); simplest and fastest here.\nAlternative: len(nums) != len(set(nums))."
  },
  {
    "objectID": "100daysofcode/Day16.html#what-i-learned-4",
    "href": "100daysofcode/Day16.html#what-i-learned-4",
    "title": "Day 16: LeetCode ‚Äì Stock, Parentheses, Palindrome, Duplicates, Sliding Window",
    "section": "what i learned",
    "text": "what i learned\n\nWhy the last[ch] &gt;= start check is essential (repeat inside window).\nWindow length formula: i - start + 1."
  },
  {
    "objectID": "100daysofcode/Day18.html#how-to-reuse",
    "href": "100daysofcode/Day18.html#how-to-reuse",
    "title": "Day 18 ‚Äî ClinVar clustered variants (SQL ‚Üí Python ‚Üí Export)",
    "section": "How to reuse",
    "text": "How to reuse\nTo Same query, same clustering, same exports on a different clinvar data set just change table name as all the columns are the same throughout all sets."
  }
]